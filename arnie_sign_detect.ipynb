{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"arnie_sign_detect.ipynb","provenance":[{"file_id":"https://github.com/luxonis/depthai-ml-training/blob/master/colab-notebooks/Easy_Object_Detection_With_Custom_Data_Demo_Training.ipynb","timestamp":1626538474453}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uQCnYPVDrsgx"},"source":["# Training Arnie the self driving car to detect signs (speed, stop lights, stop)\n","\n","Author: Warren Harper\n","\n","Date: 2021-11-07\n","\n","This model is the training portion of my final year Computer Science project for WGU. I will be using photos of objects to train a prexisting model in order to teach Arnie (the car) how to detect and respond to various signs.\n"]},{"cell_type":"code","metadata":{"id":"pH1x08R-yM-L","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"ok","timestamp":1626787631529,"user_tz":420,"elapsed":9162,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"b240f988-8670-41b7-b49f-f7712a556d78"},"source":["# After this cell executes runtime will restart to finish the install\n","!pip install numpy==1.17.5;"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting numpy==1.17.5\n","  Downloading numpy-1.17.5-cp37-cp37m-manylinux1_x86_64.whl (20.0 MB)\n","\u001b[K     |████████████████████████████████| 20.0 MB 1.1 MB/s \n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.17.5 which is incompatible.\n","kapre 0.3.5 requires numpy>=1.18.5, but you have numpy 1.17.5 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed numpy-1.17.5\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"9z8kgcs0E7iV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626787647596,"user_tz":420,"elapsed":3426,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"1c9ffa99-52f3-4280-a0b4-42644639aa84"},"source":["%tensorflow_version 1.15\n","!pip install tf_slim"],"execution_count":1,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.15`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n","Collecting tf_slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 8.2 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Rp86zMRt3Rmb"},"source":["##Select and configure the model"]},{"cell_type":"code","metadata":{"id":"gnNXNQCjdniL","executionInfo":{"status":"ok","timestamp":1626787651333,"user_tz":420,"elapsed":122,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}}},"source":["\n","num_steps = 10000  # A step means using a single batch of data. larger batch, less steps required\n","#Number of evaluation steps.\n","num_eval_steps = 100\n","#Batch size 24 is a setting that generally works well. can be changed higher or lower \n","MODELS_CONFIG = {\n","        'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 24\n","    },\n","    # http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz\n","    'ssd_mobilenet_v2_quantized': {\n","        'model_name': 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03',\n","        'pipeline_file': 'ssd_mobilenet_v2_quantized_300x300_coco.config',\n","        'batch_size': 24\n","    }\n","}\n","selected_model = 'ssd_mobilenet_v2_quantized'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colab's GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w4V-XE6kbkc1"},"source":["## Clone the `Arnie` repository containing training files"]},{"cell_type":"code","metadata":{"id":"dxc3DmvLQF3z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626787662417,"user_tz":420,"elapsed":6719,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"779467b5-a2c1-4a8b-d951-931c23d0f108"},"source":["repo_url = 'https://github.com/wnharper/arnie'\n","import os\n","%cd /content\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","!rm -rf {repo_dir_path}\n","!git clone {repo_url} {repo_dir_path}\n","%cd {repo_dir_path}\n","!git pull"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into '/content/arnie'...\n","remote: Enumerating objects: 1835, done.\u001b[K\n","remote: Total 1835 (delta 0), reused 0 (delta 0), pack-reused 1835\u001b[K\n","Receiving objects: 100% (1835/1835), 145.77 MiB | 32.12 MiB/s, done.\n","Resolving deltas: 100% (180/180), done.\n","/content/arnie\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pHUcVDSEfuCE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626787666260,"user_tz":420,"elapsed":152,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"904dae46-5c4f-4b58-f4f0-3d97f5842b68"},"source":["# quick check for training data files.\n","!ls /content/arnie/models/object_detection/data/images/train"],"execution_count":4,"outputs":[{"output_type":"stream","text":["new_signs_1626736408.jpg  new_signs_1626736734.jpg  new_signs_1626737685.jpg\n","new_signs_1626736408.xml  new_signs_1626736734.xml  new_signs_1626737685.xml\n","new_signs_1626736420.jpg  new_signs_1626736786.jpg  new_signs_1626737706.jpg\n","new_signs_1626736420.xml  new_signs_1626736786.xml  new_signs_1626737706.xml\n","new_signs_1626736433.jpg  new_signs_1626736832.jpg  new_signs_1626737726.jpg\n","new_signs_1626736433.xml  new_signs_1626736832.xml  new_signs_1626737726.xml\n","new_signs_1626736444.jpg  new_signs_1626736859.jpg  new_signs_1626737738.jpg\n","new_signs_1626736444.xml  new_signs_1626736859.xml  new_signs_1626737738.xml\n","new_signs_1626736464.jpg  new_signs_1626736877.jpg  new_signs_1626737759.jpg\n","new_signs_1626736464.xml  new_signs_1626736877.xml  new_signs_1626737759.xml\n","new_signs_1626736474.jpg  new_signs_1626736905.jpg  new_signs_1626737773.jpg\n","new_signs_1626736474.xml  new_signs_1626736905.xml  new_signs_1626737773.xml\n","new_signs_1626736510.jpg  new_signs_1626736944.jpg  new_signs_1626737791.jpg\n","new_signs_1626736510.xml  new_signs_1626736944.xml  new_signs_1626737791.xml\n","new_signs_1626736521.jpg  new_signs_1626736961.jpg  new_signs_1626737816.jpg\n","new_signs_1626736521.xml  new_signs_1626736961.xml  new_signs_1626737816.xml\n","new_signs_1626736538.jpg  new_signs_1626737003.jpg  new_signs_1626737855.jpg\n","new_signs_1626736538.xml  new_signs_1626737003.xml  new_signs_1626737855.xml\n","new_signs_1626736548.jpg  new_signs_1626737022.jpg  new_signs_1626737885.jpg\n","new_signs_1626736548.xml  new_signs_1626737022.xml  new_signs_1626737885.xml\n","new_signs_1626736569.jpg  new_signs_1626737040.jpg  new_signs_1626737898.jpg\n","new_signs_1626736569.xml  new_signs_1626737040.xml  new_signs_1626737898.xml\n","new_signs_1626736579.jpg  new_signs_1626737059.jpg  new_signs_1626737930.jpg\n","new_signs_1626736579.xml  new_signs_1626737059.xml  new_signs_1626737930.xml\n","new_signs_1626736596.jpg  new_signs_1626737076.jpg  new_signs_1626737953.jpg\n","new_signs_1626736596.xml  new_signs_1626737076.xml  new_signs_1626737953.xml\n","new_signs_1626736633.jpg  new_signs_1626737103.jpg  new_signs_1626737966.jpg\n","new_signs_1626736633.xml  new_signs_1626737103.xml  new_signs_1626737966.xml\n","new_signs_1626736651.jpg  new_signs_1626737121.jpg  new_signs_1626737976.jpg\n","new_signs_1626736651.xml  new_signs_1626737121.xml  new_signs_1626737976.xml\n","new_signs_1626736669.jpg  new_signs_1626737600.jpg  new_signs_1626738013.jpg\n","new_signs_1626736669.xml  new_signs_1626737600.xml  new_signs_1626738013.xml\n","new_signs_1626736718.jpg  new_signs_1626737621.jpg\n","new_signs_1626736718.xml  new_signs_1626737621.xml\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bI8__uNS8-ns"},"source":["# Install Tensorflow Object Detection API\n","\n","Clone TF models which contains the Object Detection API; also install the required dependencies\n"]},{"cell_type":"code","metadata":{"id":"ecpHEnka8Kix","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626787723384,"user_tz":420,"elapsed":47295,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"7877c9a4-7503-484b-f8a7-7746ba8d4264"},"source":["# %%capture\n","%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","%cd /content/models/\n","!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n","!apt-get update && apt-get install -y -qq protobuf-compiler python-pil python-lxml python-tk\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","!pip install -q pycocotools\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","!python object_detection/builders/model_builder_test.py"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content\n","/content/models\n","Note: checking out '58d19c67e1d30d905dd5c6e5092348658fed80af'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by performing another checkout.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -b with the checkout command again. Example:\n","\n","  git checkout -b <new-branch-name>\n","\n","HEAD is now at 58d19c67 Internal change\n","Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,418 kB]\n","Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,783 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,188 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,658 kB]\n","Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [912 kB]\n","Fetched 9,231 kB in 4s (2,504 kB/s)\n","Reading package lists... Done\n","Selecting previously unselected package python-bs4.\n","(Reading database ... 160837 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.4_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.6_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.6) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.6) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","/content/models/research\n","object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u-k7uGThXlny"},"source":["## Prepare `tfrecord` files\n","\n"]},{"cell_type":"code","metadata":{"id":"ezGDABRXXhPP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626787733735,"user_tz":420,"elapsed":5034,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"6f741926-3a28-4763-bfb9-4202c273be72"},"source":["#%%capture\n","#%cd {repo_dir_path}\n","%cd /content/arnie/models/object_detection/\n","# Convert train folder annotation xml files to a single csv file,\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\n","!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n","\n","# Convert test folder annotation xml files to a single csv.\n","!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n","\n","# Generate `train.record`\n","!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n","\n","# Generate `test.record`\n","!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n","\n","# Set the paths\n","test_record_fname = '/content/arnie/models/object_detection/data/annotations/test.record'\n","train_record_fname = '/content/arnie/models/object_detection/data/annotations/train.record'\n","label_map_pbtxt_fname = '/content/arnie/models/object_detection/data/annotations/label_map.pbtxt'\n","\n","print(\"done\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/arnie/models/object_detection\n","Successfully converted xml to csv.\n","Generate `data/annotations/label_map.pbtxt`\n","Successfully converted xml to csv.\n","Successfully created the TFRecords: /content/arnie/models/object_detection/data/annotations/train.record\n","Successfully created the TFRecords: /content/arnie/models/object_detection/data/annotations/test.record\n","done\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iCNYAaC7w6N8"},"source":["## Download the Mobilenet SSD v2 Model"]},{"cell_type":"code","metadata":{"id":"orDCj6ihgUMR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626787742159,"user_tz":420,"elapsed":3099,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"a4b8c680-64bc-4d9e-a891-2e90c1809f91"},"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)\n","!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/models/research\n","/content/models/research/pretrained_model\n","total 204M\n","drwx------  2 303230 5000 4.0K Jan  4  2019 .\n","drwxr-xr-x 63 root   root 4.0K Jul 20 13:29 ..\n","-rw-------  1 303230 5000  93M Jan  4  2019 model.ckpt.data-00000-of-00001\n","-rw-------  1 303230 5000  68K Jan  4  2019 model.ckpt.index\n","-rw-------  1 303230 5000  20M Jan  4  2019 model.ckpt.meta\n","-rw-------  1 303230 5000 4.3K Jan  4  2019 pipeline.config\n","-rw-------  1 303230 5000  24M Jan  4  2019 tflite_graph.pb\n","-rw-------  1 303230 5000  68M Jan  4  2019 tflite_graph.pbtxt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UHnxlfRznPP3","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1626787746571,"user_tz":420,"elapsed":134,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"186a8d62-b668-4586-a697-b5a0d3e5c9fa"},"source":["#TF pretrained model checkpoint\n","fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/models/research/pretrained_model/model.ckpt'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"MvwtHlLOeRJD"},"source":["## Configuring a Training Pipeline"]},{"cell_type":"code","metadata":{"id":"dIhw7IdpLuiU","executionInfo":{"status":"ok","timestamp":1626787753195,"user_tz":420,"elapsed":131,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}}},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"FRofNAq5GDXY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626787755970,"user_tz":420,"elapsed":254,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"eb7d1480-43f4-447d-a0d5-f26d2e17bbec"},"source":["from pathlib import Path\n","parent = Path(label_map_pbtxt_fname).parent\n","!ls {parent}"],"execution_count":10,"outputs":[{"output_type":"stream","text":["label_map.pbtxt  test_labels.csv  test.record  train_labels.csv  train.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YjtCbLF2i0wI","executionInfo":{"status":"ok","timestamp":1626787759903,"user_tz":420,"elapsed":1233,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}}},"source":["import re\n","iou_threshold = 0.50\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    # Set number of classes num_classes.\n","    s = re.sub('iou_threshold: [0-9].[0-9]+',\n","               'iou_threshold: {}'.format(iou_threshold), s)\n","    \n","    f.write(s)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"GH0MEEanocn6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626787766110,"user_tz":420,"elapsed":324,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"f728066a-37e2-4b94-efe3-4939932cb76b"},"source":["# #Have a look at the config file with various settings\n","!cat {pipeline_fname}"],"execution_count":12,"outputs":[{"output_type":"stream","text":["# Quantized trained SSD with Mobilenet v2 on MSCOCO Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","model {\n","  ssd {\n","    num_classes: 5\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.03\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.9997,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.9997,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid {\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      hard_example_miner {\n","        num_hard_examples: 3000\n","        iou_threshold: 0.5\n","        loss_type: CLASSIFICATION\n","        max_negatives_per_positive: 3\n","        min_negatives_per_image: 3\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 24\n","  optimizer {\n","    rms_prop_optimizer: {\n","      learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.004\n","          decay_steps: 800720\n","          decay_factor: 0.95\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","      decay: 0.9\n","      epsilon: 1.0\n","    }\n","  }\n","  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n","  fine_tune_checkpoint_type:  \"detection\"\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 10000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/arnie/models/object_detection/data/annotations/train.record\"\n","  }\n","  label_map_path: \"/content/arnie/models/object_detection/data/annotations/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  num_examples: 8000\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  max_evals: 10\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/arnie/models/object_detection/data/annotations/test.record\"\n","  }\n","  label_map_path: \"/content/arnie/models/object_detection/data/annotations/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}\n","\n","graph_rewriter {\n","  quantization {\n","    delay: 48000\n","    weight_bits: 8\n","    activation_bits: 8\n","  }\n","}"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JDddx2rPfex9"},"source":["# Train the model"]},{"cell_type":"markdown","metadata":{"id":"PS6W4ZEEWBgM"},"source":["##[Optional] The cell below adds Tensorboard visualization to the training process.\n","Will open in new tab."]},{"cell_type":"code","metadata":{"id":"f11w0uO3jFCB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626787816501,"user_tz":420,"elapsed":10692,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"3f49452c-4961-424f-d8cc-9db09cd2e46d"},"source":["#After running this cell click on the link in the output cell to open tensorboard\n","#Tensoarboard will show you graphically different training parameters as the model is training\n","#when training finishes after the set number of steps, tensorboard can be used to see a nice summary of the training process\n","#Visuals will load in Tensorboard after the model has gone through a few hundred steps\n","\n","model_dir = 'training/'\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip\n","LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","get_ipython().system_raw('./ngrok http 6006 &')\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":14,"outputs":[{"output_type":"stream","text":["--2021-07-20 13:30:05--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 34.228.108.156, 52.201.162.28, 52.44.39.24, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|34.228.108.156|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13832437 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n","\n","ngrok-stable-linux- 100%[===================>]  13.19M  18.4MB/s    in 0.7s    \n","\n","2021-07-20 13:30:06 (18.4 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13832437/13832437]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n","  inflating: ngrok                   \n","https://30239a40aecc.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zOyWAHNywiL4"},"source":["## Start the training"]},{"cell_type":"code","metadata":{"id":"CjDHjhKQofT5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626794978375,"user_tz":420,"elapsed":697119,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"b0e59f6b-6b35-40ff-c82e-dd360076d17f"},"source":["model_dir = 'training/'\n","# Optionally remove content in output model directory for a fresh start.\n","!rm -rf {model_dir}\n","os.makedirs(model_dir, exist_ok=True)\n","!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":15,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0720 13:30:46.796413 139770316203904 model_lib.py:717] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting train_steps: 10000\n","I0720 13:30:46.796702 139770316203904 config_util.py:552] Maybe overwriting train_steps: 10000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0720 13:30:46.796797 139770316203904 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0720 13:30:46.796880 139770316203904 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0720 13:30:46.796961 139770316203904 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","INFO:tensorflow:Maybe overwriting load_pretrained: True\n","I0720 13:30:46.797033 139770316203904 config_util.py:552] Maybe overwriting load_pretrained: True\n","INFO:tensorflow:Ignoring config override key: load_pretrained\n","I0720 13:30:46.797105 139770316203904 config_util.py:562] Ignoring config override key: load_pretrained\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0720 13:30:46.797358 139770316203904 model_lib.py:733] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","I0720 13:30:46.797482 139770316203904 model_lib.py:768] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1e63537890>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I0720 13:30:46.798011 139770316203904 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1e63537890>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f1e63b2bef0>) includes params argument, but params are not passed to Estimator.\n","W0720 13:30:46.798274 139770316203904 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f1e63b2bef0>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I0720 13:30:46.798742 139770316203904 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I0720 13:30:46.798949 139770316203904 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I0720 13:30:46.799165 139770316203904 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0720 13:30:46.812290 139770316203904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0720 13:30:46.835530 139770316203904 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0720 13:30:46.840193 139770316203904 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0720 13:30:46.860216 139770316203904 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1e63b2c690>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 13:30:46.893430 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1e63b2c690>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f1e635523b0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 13:30:47.074706 139770316203904 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f1e635523b0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0720 13:30:47.081102 139770316203904 deprecation.py:323] From /content/models/research/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0720 13:30:47.088809 139770316203904 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0720 13:30:47.178740 139770316203904 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0720 13:30:47.900525 139770316203904 deprecation.py:323] From /content/models/research/object_detection/inputs.py:260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Calling model_fn.\n","I0720 13:30:48.339289 139770316203904 estimator.py:1148] Calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0720 13:30:48.823536 139770316203904 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:30:51.304032 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:30:51.337096 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:30:51.366344 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:30:51.395049 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:30:51.425210 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:30:51.457281 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 13:31:04.148334 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 13:31:04.148828 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 13:31:04.149379 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 13:31:04.149722 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 13:31:04.150249 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 13:31:04.150583 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 13:31:04.151109 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 13:31:04.151441 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 13:31:04.151954 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 13:31:04.152273 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 13:31:04.152799 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 13:31:04.153121 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 13:31:04.153641 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 13:31:04.153954 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 13:31:04.154499 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 13:31:04.154877 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 13:31:04.155546 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 13:31:04.155918 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 13:31:04.156457 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 13:31:04.156766 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 13:31:04.157279 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 13:31:04.157615 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 13:31:04.158145 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 13:31:04.158468 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 13:31:04.158977 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 13:31:04.159291 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 13:31:04.159868 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 13:31:04.160234 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 13:31:04.160854 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 13:31:04.161173 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 13:31:04.161694 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 13:31:04.162010 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 13:31:04.162541 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 13:31:04.162858 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 13:31:04.163389 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 13:31:04.163699 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 13:31:04.163990 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 13:31:04.164287 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 13:31:04.164583 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 13:31:04.164867 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 13:31:04.165158 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 13:31:04.165475 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 13:31:04.165776 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0720 13:31:11.544556 139770316203904 deprecation.py:506] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","INFO:tensorflow:Done calling model_fn.\n","I0720 13:31:17.520712 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I0720 13:31:17.521922 139770316203904 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I0720 13:31:23.129018 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 13:31:23.139242: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2021-07-20 13:31:23.139519: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5557ff9f1a40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 13:31:23.139553: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-07-20 13:31:23.144297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-07-20 13:31:23.446995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:31:23.447764: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5557ff9f16c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 13:31:23.447794: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2021-07-20 13:31:23.448845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:31:23.449382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 13:31:23.493551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 13:31:23.680017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 13:31:23.930879: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 13:31:23.955208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 13:31:24.140173: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 13:31:24.178072: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 13:31:24.541433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 13:31:24.541652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:31:24.542316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:31:24.542859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 13:31:24.545681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 13:31:24.547060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 13:31:24.547095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 13:31:24.547110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 13:31:24.548232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:31:24.549230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:31:24.550032: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-07-20 13:31:24.550092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Running local_init_op.\n","I0720 13:31:34.694513 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 13:31:35.339036 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n","I0720 13:31:52.808460 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n","2021-07-20 13:32:21.382537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 13:32:24.487950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","INFO:tensorflow:loss = 23.52627, step = 0\n","I0720 13:32:27.438097 139770316203904 basic_session_run_hooks.py:262] loss = 23.52627, step = 0\n","INFO:tensorflow:global_step/sec: 1.10527\n","I0720 13:33:57.913262 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.10527\n","INFO:tensorflow:loss = 2.097859, step = 100 (90.477 sec)\n","I0720 13:33:57.914603 139770316203904 basic_session_run_hooks.py:260] loss = 2.097859, step = 100 (90.477 sec)\n","INFO:tensorflow:global_step/sec: 1.47082\n","I0720 13:35:05.902646 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.47082\n","INFO:tensorflow:loss = 1.5854595, step = 200 (67.989 sec)\n","I0720 13:35:05.903784 139770316203904 basic_session_run_hooks.py:260] loss = 1.5854595, step = 200 (67.989 sec)\n","INFO:tensorflow:global_step/sec: 1.46358\n","I0720 13:36:14.228154 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46358\n","INFO:tensorflow:loss = 1.5708054, step = 300 (68.325 sec)\n","I0720 13:36:14.229232 139770316203904 basic_session_run_hooks.py:260] loss = 1.5708054, step = 300 (68.325 sec)\n","INFO:tensorflow:global_step/sec: 1.46289\n","I0720 13:37:22.586097 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46289\n","INFO:tensorflow:loss = 1.6295395, step = 400 (68.358 sec)\n","I0720 13:37:22.587320 139770316203904 basic_session_run_hooks.py:260] loss = 1.6295395, step = 400 (68.358 sec)\n","INFO:tensorflow:global_step/sec: 1.46696\n","I0720 13:38:30.754167 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46696\n","INFO:tensorflow:loss = 1.4447944, step = 500 (68.168 sec)\n","I0720 13:38:30.755399 139770316203904 basic_session_run_hooks.py:260] loss = 1.4447944, step = 500 (68.168 sec)\n","INFO:tensorflow:global_step/sec: 1.4661\n","I0720 13:39:38.962554 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.4661\n","INFO:tensorflow:loss = 1.3578694, step = 600 (68.209 sec)\n","I0720 13:39:38.963879 139770316203904 basic_session_run_hooks.py:260] loss = 1.3578694, step = 600 (68.209 sec)\n","INFO:tensorflow:global_step/sec: 1.46069\n","I0720 13:40:47.423403 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46069\n","INFO:tensorflow:loss = 1.1387545, step = 700 (68.461 sec)\n","I0720 13:40:47.424748 139770316203904 basic_session_run_hooks.py:260] loss = 1.1387545, step = 700 (68.461 sec)\n","INFO:tensorflow:global_step/sec: 1.47045\n","I0720 13:41:55.430000 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.47045\n","INFO:tensorflow:loss = 1.8803824, step = 800 (68.006 sec)\n","I0720 13:41:55.431087 139770316203904 basic_session_run_hooks.py:260] loss = 1.8803824, step = 800 (68.006 sec)\n","INFO:tensorflow:Saving checkpoints for 804 into training/model.ckpt.\n","I0720 13:41:57.495110 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 804 into training/model.ckpt.\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1e4a561310>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 13:42:00.013401 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1e4a561310>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1e56a4e710> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 13:42:00.178323 139770316203904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1e56a4e710> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0720 13:42:00.637955 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:42:02.890523 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:42:02.920073 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:42:02.953933 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:42:03.014111 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:42:03.046952 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:42:03.074100 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 13:42:05.077294 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 13:42:05.077605 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 13:42:05.077872 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 13:42:05.078046 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 13:42:05.078295 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 13:42:05.078471 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 13:42:05.078707 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 13:42:05.078873 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 13:42:05.079111 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 13:42:05.079275 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 13:42:05.079515 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 13:42:05.079695 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 13:42:05.079928 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 13:42:05.080101 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 13:42:05.080340 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 13:42:05.080510 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 13:42:05.080742 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 13:42:05.080912 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 13:42:05.081157 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 13:42:05.081321 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 13:42:05.081561 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 13:42:05.081725 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 13:42:05.081966 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 13:42:05.082139 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 13:42:05.082378 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 13:42:05.082547 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 13:42:05.082788 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 13:42:05.082978 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 13:42:05.083235 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 13:42:05.083408 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 13:42:05.083643 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 13:42:05.083809 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 13:42:05.084055 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 13:42:05.084247 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 13:42:05.084496 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 13:42:05.084664 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 13:42:05.084827 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 13:42:05.084990 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 13:42:05.085162 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 13:42:05.085329 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 13:42:05.085500 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 13:42:05.085668 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 13:42:05.085835 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0720 13:42:05.107757 139770316203904 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0720 13:42:05.275070 139770316203904 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Done calling model_fn.\n","I0720 13:42:05.936791 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-07-20T13:42:05Z\n","I0720 13:42:05.951941 139770316203904 evaluation.py:255] Starting evaluation at 2021-07-20T13:42:05Z\n","INFO:tensorflow:Graph was finalized.\n","I0720 13:42:06.648368 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 13:42:06.649503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:42:06.649811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 13:42:06.649908: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 13:42:06.649934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 13:42:06.649961: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 13:42:06.649982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 13:42:06.650009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 13:42:06.650032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 13:42:06.650057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 13:42:06.650138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:42:06.650421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:42:06.650620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 13:42:06.650679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 13:42:06.650692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 13:42:06.650703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 13:42:06.650800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:42:06.651127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:42:06.651433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-804\n","I0720 13:42:06.652702 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-804\n","INFO:tensorflow:Running local_init_op.\n","I0720 13:42:08.164971 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 13:42:08.321719 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 4 images.\n","I0720 13:42:11.393237 139766408148736 coco_evaluation.py:237] Performing evaluation on 4 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0720 13:42:11.393735 139766408148736 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0720 13:42:11.394124 139766408148736 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.05s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.590\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.616\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.580\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.620\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Finished evaluation at 2021-07-20-13:42:11\n","I0720 13:42:11.900809 139770316203904 evaluation.py:275] Finished evaluation at 2021-07-20-13:42:11\n","INFO:tensorflow:Saving dict for global step 804: DetectionBoxes_Precision/mAP = 0.5899175, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.57978547, DetectionBoxes_Precision/mAP (small) = 0.6, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 0.61633664, DetectionBoxes_Recall/AR@1 = 0.62, DetectionBoxes_Recall/AR@10 = 0.62, DetectionBoxes_Recall/AR@100 = 0.62, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.61833334, DetectionBoxes_Recall/AR@100 (small) = 0.6, Loss/classification_loss = 0.9962477, Loss/localization_loss = 0.48563886, Loss/regularization_loss = 0.3465706, Loss/total_loss = 1.8284571, global_step = 804, learning_rate = 0.004, loss = 1.8284571\n","I0720 13:42:11.901095 139770316203904 estimator.py:2049] Saving dict for global step 804: DetectionBoxes_Precision/mAP = 0.5899175, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.57978547, DetectionBoxes_Precision/mAP (small) = 0.6, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 0.61633664, DetectionBoxes_Recall/AR@1 = 0.62, DetectionBoxes_Recall/AR@10 = 0.62, DetectionBoxes_Recall/AR@100 = 0.62, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.61833334, DetectionBoxes_Recall/AR@100 (small) = 0.6, Loss/classification_loss = 0.9962477, Loss/localization_loss = 0.48563886, Loss/regularization_loss = 0.3465706, Loss/total_loss = 1.8284571, global_step = 804, learning_rate = 0.004, loss = 1.8284571\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 804: training/model.ckpt-804\n","I0720 13:42:12.877338 139770316203904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 804: training/model.ckpt-804\n","INFO:tensorflow:global_step/sec: 1.1925\n","I0720 13:43:19.287465 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.1925\n","INFO:tensorflow:loss = 1.22652, step = 900 (83.858 sec)\n","I0720 13:43:19.288767 139770316203904 basic_session_run_hooks.py:260] loss = 1.22652, step = 900 (83.858 sec)\n","INFO:tensorflow:global_step/sec: 1.46493\n","I0720 13:44:27.550331 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46493\n","INFO:tensorflow:loss = 1.1187767, step = 1000 (68.263 sec)\n","I0720 13:44:27.551584 139770316203904 basic_session_run_hooks.py:260] loss = 1.1187767, step = 1000 (68.263 sec)\n","INFO:tensorflow:global_step/sec: 1.46409\n","I0720 13:45:35.852201 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46409\n","INFO:tensorflow:loss = 1.30793, step = 1100 (68.302 sec)\n","I0720 13:45:35.853579 139770316203904 basic_session_run_hooks.py:260] loss = 1.30793, step = 1100 (68.302 sec)\n","INFO:tensorflow:global_step/sec: 1.45902\n","I0720 13:46:44.391544 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.45902\n","INFO:tensorflow:loss = 1.6917884, step = 1200 (68.539 sec)\n","I0720 13:46:44.392699 139770316203904 basic_session_run_hooks.py:260] loss = 1.6917884, step = 1200 (68.539 sec)\n","INFO:tensorflow:global_step/sec: 1.46439\n","I0720 13:47:52.679211 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46439\n","INFO:tensorflow:loss = 1.0980611, step = 1300 (68.288 sec)\n","I0720 13:47:52.680697 139770316203904 basic_session_run_hooks.py:260] loss = 1.0980611, step = 1300 (68.288 sec)\n","INFO:tensorflow:global_step/sec: 1.46051\n","I0720 13:49:01.148224 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46051\n","INFO:tensorflow:loss = 1.3171127, step = 1400 (68.469 sec)\n","I0720 13:49:01.149323 139770316203904 basic_session_run_hooks.py:260] loss = 1.3171127, step = 1400 (68.469 sec)\n","INFO:tensorflow:global_step/sec: 1.46384\n","I0720 13:50:09.461823 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46384\n","INFO:tensorflow:loss = 1.2244674, step = 1500 (68.314 sec)\n","I0720 13:50:09.463006 139770316203904 basic_session_run_hooks.py:260] loss = 1.2244674, step = 1500 (68.314 sec)\n","INFO:tensorflow:global_step/sec: 1.46535\n","I0720 13:51:17.704743 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46535\n","INFO:tensorflow:loss = 1.2274512, step = 1600 (68.243 sec)\n","I0720 13:51:17.705865 139770316203904 basic_session_run_hooks.py:260] loss = 1.2274512, step = 1600 (68.243 sec)\n","INFO:tensorflow:Saving checkpoints for 1660 into training/model.ckpt.\n","I0720 13:51:58.128368 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 1660 into training/model.ckpt.\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1e569d4d10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 13:52:00.506353 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1e569d4d10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1cc264c200> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 13:52:00.664868 139770316203904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1cc264c200> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0720 13:52:01.114225 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:52:03.035815 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:52:03.066932 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:52:03.097486 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:52:03.127828 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:52:03.156605 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 13:52:03.185113 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 13:52:05.267404 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 13:52:05.267707 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 13:52:05.267978 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 13:52:05.268155 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 13:52:05.268411 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 13:52:05.268589 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 13:52:05.268885 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 13:52:05.269101 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 13:52:05.269356 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 13:52:05.269531 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 13:52:05.269785 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 13:52:05.269957 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 13:52:05.270189 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 13:52:05.270371 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 13:52:05.270638 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 13:52:05.270807 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 13:52:05.271046 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 13:52:05.271213 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 13:52:05.271456 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 13:52:05.271628 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 13:52:05.271862 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 13:52:05.272027 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 13:52:05.272262 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 13:52:05.272437 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 13:52:05.272682 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 13:52:05.272849 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 13:52:05.273082 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 13:52:05.273245 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 13:52:05.273487 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 13:52:05.273664 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 13:52:05.273911 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 13:52:05.274092 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 13:52:05.274339 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 13:52:05.274512 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 13:52:05.274792 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 13:52:05.274975 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 13:52:05.275143 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 13:52:05.275312 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 13:52:05.275484 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 13:52:05.275654 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 13:52:05.275821 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 13:52:05.275986 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 13:52:05.276149 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I0720 13:52:06.124491 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-07-20T13:52:06Z\n","I0720 13:52:06.139369 139770316203904 evaluation.py:255] Starting evaluation at 2021-07-20T13:52:06Z\n","INFO:tensorflow:Graph was finalized.\n","I0720 13:52:07.281236 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 13:52:07.282002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:52:07.282305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 13:52:07.282443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 13:52:07.282477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 13:52:07.282502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 13:52:07.282525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 13:52:07.282545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 13:52:07.282568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 13:52:07.282590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 13:52:07.282693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:52:07.282974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:52:07.283179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 13:52:07.283224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 13:52:07.283239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 13:52:07.283249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 13:52:07.283352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:52:07.283629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 13:52:07.283864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-1660\n","I0720 13:52:07.284938 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-1660\n","INFO:tensorflow:Running local_init_op.\n","I0720 13:52:08.873117 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 13:52:09.065071 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 4 images.\n","I0720 13:52:11.988981 139766416541440 coco_evaluation.py:237] Performing evaluation on 4 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0720 13:52:11.989345 139766416541440 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0720 13:52:11.989701 139766416541440 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.698\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.950\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.703\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.715\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.715\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.715\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.715\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Finished evaluation at 2021-07-20-13:52:12\n","I0720 13:52:12.484004 139770316203904 evaluation.py:275] Finished evaluation at 2021-07-20-13:52:12\n","INFO:tensorflow:Saving dict for global step 1660: DetectionBoxes_Precision/mAP = 0.6984158, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.70316833, DetectionBoxes_Precision/mAP (small) = 0.7, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 0.95049506, DetectionBoxes_Recall/AR@1 = 0.715, DetectionBoxes_Recall/AR@10 = 0.715, DetectionBoxes_Recall/AR@100 = 0.715, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.715, DetectionBoxes_Recall/AR@100 (small) = 0.7, Loss/classification_loss = 0.57527566, Loss/localization_loss = 0.26346332, Loss/regularization_loss = 0.3459433, Loss/total_loss = 1.1846824, global_step = 1660, learning_rate = 0.004, loss = 1.1846824\n","I0720 13:52:12.484287 139770316203904 estimator.py:2049] Saving dict for global step 1660: DetectionBoxes_Precision/mAP = 0.6984158, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.70316833, DetectionBoxes_Precision/mAP (small) = 0.7, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 0.95049506, DetectionBoxes_Recall/AR@1 = 0.715, DetectionBoxes_Recall/AR@10 = 0.715, DetectionBoxes_Recall/AR@100 = 0.715, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.715, DetectionBoxes_Recall/AR@100 (small) = 0.7, Loss/classification_loss = 0.57527566, Loss/localization_loss = 0.26346332, Loss/regularization_loss = 0.3459433, Loss/total_loss = 1.1846824, global_step = 1660, learning_rate = 0.004, loss = 1.1846824\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1660: training/model.ckpt-1660\n","I0720 13:52:12.486050 139770316203904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1660: training/model.ckpt-1660\n","INFO:tensorflow:global_step/sec: 1.20786\n","I0720 13:52:40.495481 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.20786\n","INFO:tensorflow:loss = 1.5279198, step = 1700 (82.791 sec)\n","I0720 13:52:40.496476 139770316203904 basic_session_run_hooks.py:260] loss = 1.5279198, step = 1700 (82.791 sec)\n","INFO:tensorflow:global_step/sec: 1.46197\n","I0720 13:53:48.896265 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46197\n","INFO:tensorflow:loss = 1.1818762, step = 1800 (68.401 sec)\n","I0720 13:53:48.897419 139770316203904 basic_session_run_hooks.py:260] loss = 1.1818762, step = 1800 (68.401 sec)\n","INFO:tensorflow:global_step/sec: 1.4592\n","I0720 13:54:57.426865 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.4592\n","INFO:tensorflow:loss = 1.1070927, step = 1900 (68.531 sec)\n","I0720 13:54:57.428142 139770316203904 basic_session_run_hooks.py:260] loss = 1.1070927, step = 1900 (68.531 sec)\n","INFO:tensorflow:global_step/sec: 1.46733\n","I0720 13:56:05.577900 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46733\n","INFO:tensorflow:loss = 0.9178492, step = 2000 (68.151 sec)\n","I0720 13:56:05.579034 139770316203904 basic_session_run_hooks.py:260] loss = 0.9178492, step = 2000 (68.151 sec)\n","INFO:tensorflow:global_step/sec: 1.46415\n","I0720 13:57:13.876976 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46415\n","INFO:tensorflow:loss = 1.0727962, step = 2100 (68.299 sec)\n","I0720 13:57:13.878268 139770316203904 basic_session_run_hooks.py:260] loss = 1.0727962, step = 2100 (68.299 sec)\n","INFO:tensorflow:global_step/sec: 1.46823\n","I0720 13:58:21.986172 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46823\n","INFO:tensorflow:loss = 1.1631444, step = 2200 (68.109 sec)\n","I0720 13:58:21.987228 139770316203904 basic_session_run_hooks.py:260] loss = 1.1631444, step = 2200 (68.109 sec)\n","INFO:tensorflow:global_step/sec: 1.45838\n","I0720 13:59:30.555555 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.45838\n","INFO:tensorflow:loss = 1.2770118, step = 2300 (68.569 sec)\n","I0720 13:59:30.556708 139770316203904 basic_session_run_hooks.py:260] loss = 1.2770118, step = 2300 (68.569 sec)\n","INFO:tensorflow:global_step/sec: 1.4645\n","I0720 14:00:38.838093 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.4645\n","INFO:tensorflow:loss = 1.395606, step = 2400 (68.283 sec)\n","I0720 14:00:38.839321 139770316203904 basic_session_run_hooks.py:260] loss = 1.395606, step = 2400 (68.283 sec)\n","INFO:tensorflow:global_step/sec: 1.46431\n","I0720 14:01:47.129757 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46431\n","INFO:tensorflow:loss = 1.3053199, step = 2500 (68.292 sec)\n","I0720 14:01:47.130973 139770316203904 basic_session_run_hooks.py:260] loss = 1.3053199, step = 2500 (68.292 sec)\n","INFO:tensorflow:Saving checkpoints for 2518 into training/model.ckpt.\n","I0720 14:01:58.724985 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 2518 into training/model.ckpt.\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1de01624d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 14:02:01.155276 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1de01624d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1cc23785f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 14:02:01.313756 139770316203904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1cc23785f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0720 14:02:01.777050 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:02:03.687917 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:02:03.715314 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:02:03.741476 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:02:03.768034 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:02:03.795798 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:02:03.822570 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 14:02:05.901145 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 14:02:05.901453 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 14:02:05.901721 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 14:02:05.901893 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 14:02:05.902134 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 14:02:05.902298 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 14:02:05.902545 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 14:02:05.902716 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 14:02:05.902952 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 14:02:05.903112 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 14:02:05.903347 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 14:02:05.903518 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 14:02:05.903756 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 14:02:05.903923 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 14:02:05.904158 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 14:02:05.904320 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 14:02:05.904564 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 14:02:05.904736 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 14:02:05.904973 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 14:02:05.905134 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 14:02:05.905367 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 14:02:05.905538 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 14:02:05.905791 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 14:02:05.905954 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 14:02:05.906190 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 14:02:05.906348 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 14:02:05.906607 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 14:02:05.906772 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 14:02:05.907012 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 14:02:05.907176 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 14:02:05.907421 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 14:02:05.907641 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 14:02:05.907982 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 14:02:05.908233 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 14:02:05.908598 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 14:02:05.908839 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 14:02:05.909050 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 14:02:05.909260 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 14:02:05.909504 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 14:02:05.909754 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 14:02:05.909991 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 14:02:05.910243 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 14:02:05.910510 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I0720 14:02:06.766323 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-07-20T14:02:06Z\n","I0720 14:02:06.781162 139770316203904 evaluation.py:255] Starting evaluation at 2021-07-20T14:02:06Z\n","INFO:tensorflow:Graph was finalized.\n","I0720 14:02:07.478071 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 14:02:07.478736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:02:07.479035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 14:02:07.479136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 14:02:07.479164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 14:02:07.479189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 14:02:07.479215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 14:02:07.479239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 14:02:07.479259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 14:02:07.479279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 14:02:07.479361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:02:07.479701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:02:07.479924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 14:02:07.480009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 14:02:07.480025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 14:02:07.480036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 14:02:07.480141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:02:07.480429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:02:07.480668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-2518\n","I0720 14:02:07.481580 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-2518\n","INFO:tensorflow:Running local_init_op.\n","I0720 14:02:08.988548 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 14:02:09.152271 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 4 images.\n","I0720 14:02:12.211938 139766416541440 coco_evaluation.py:237] Performing evaluation on 4 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0720 14:02:12.212273 139766416541440 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0720 14:02:12.213600 139766416541440 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.913\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.694\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.730\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.730\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.737\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Finished evaluation at 2021-07-20-14:02:12\n","I0720 14:02:12.701593 139770316203904 evaluation.py:275] Finished evaluation at 2021-07-20-14:02:12\n","INFO:tensorflow:Saving dict for global step 2518: DetectionBoxes_Precision/mAP = 0.6907261, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.6938944, DetectionBoxes_Precision/mAP (small) = 0.6, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 0.9128713, DetectionBoxes_Recall/AR@1 = 0.73, DetectionBoxes_Recall/AR@10 = 0.73, DetectionBoxes_Recall/AR@100 = 0.73, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.7366667, DetectionBoxes_Recall/AR@100 (small) = 0.6, Loss/classification_loss = 0.33034664, Loss/localization_loss = 0.28588834, Loss/regularization_loss = 0.34523445, Loss/total_loss = 0.9614695, global_step = 2518, learning_rate = 0.004, loss = 0.9614695\n","I0720 14:02:12.701876 139770316203904 estimator.py:2049] Saving dict for global step 2518: DetectionBoxes_Precision/mAP = 0.6907261, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.6938944, DetectionBoxes_Precision/mAP (small) = 0.6, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 0.9128713, DetectionBoxes_Recall/AR@1 = 0.73, DetectionBoxes_Recall/AR@10 = 0.73, DetectionBoxes_Recall/AR@100 = 0.73, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.7366667, DetectionBoxes_Recall/AR@100 (small) = 0.6, Loss/classification_loss = 0.33034664, Loss/localization_loss = 0.28588834, Loss/regularization_loss = 0.34523445, Loss/total_loss = 0.9614695, global_step = 2518, learning_rate = 0.004, loss = 0.9614695\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2518: training/model.ckpt-2518\n","I0720 14:02:12.704219 139770316203904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2518: training/model.ckpt-2518\n","INFO:tensorflow:global_step/sec: 1.21376\n","I0720 14:03:09.518592 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.21376\n","INFO:tensorflow:loss = 1.2411149, step = 2600 (82.389 sec)\n","I0720 14:03:09.519749 139770316203904 basic_session_run_hooks.py:260] loss = 1.2411149, step = 2600 (82.389 sec)\n","INFO:tensorflow:global_step/sec: 1.46532\n","I0720 14:04:17.762828 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46532\n","INFO:tensorflow:loss = 1.1956072, step = 2700 (68.245 sec)\n","I0720 14:04:17.764746 139770316203904 basic_session_run_hooks.py:260] loss = 1.1956072, step = 2700 (68.245 sec)\n","INFO:tensorflow:global_step/sec: 1.46283\n","I0720 14:05:26.123404 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46283\n","INFO:tensorflow:loss = 1.02097, step = 2800 (68.360 sec)\n","I0720 14:05:26.124752 139770316203904 basic_session_run_hooks.py:260] loss = 1.02097, step = 2800 (68.360 sec)\n","INFO:tensorflow:global_step/sec: 1.46858\n","I0720 14:06:34.216322 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46858\n","INFO:tensorflow:loss = 1.2769524, step = 2900 (68.093 sec)\n","I0720 14:06:34.217378 139770316203904 basic_session_run_hooks.py:260] loss = 1.2769524, step = 2900 (68.093 sec)\n","INFO:tensorflow:global_step/sec: 1.46655\n","I0720 14:07:42.403382 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46655\n","INFO:tensorflow:loss = 1.0205461, step = 3000 (68.187 sec)\n","I0720 14:07:42.404679 139770316203904 basic_session_run_hooks.py:260] loss = 1.0205461, step = 3000 (68.187 sec)\n","INFO:tensorflow:global_step/sec: 1.46804\n","I0720 14:08:50.521275 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46804\n","INFO:tensorflow:loss = 1.1660445, step = 3100 (68.118 sec)\n","I0720 14:08:50.522626 139770316203904 basic_session_run_hooks.py:260] loss = 1.1660445, step = 3100 (68.118 sec)\n","INFO:tensorflow:global_step/sec: 1.46789\n","I0720 14:09:58.646049 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46789\n","INFO:tensorflow:loss = 1.1185884, step = 3200 (68.125 sec)\n","I0720 14:09:58.647267 139770316203904 basic_session_run_hooks.py:260] loss = 1.1185884, step = 3200 (68.125 sec)\n","INFO:tensorflow:global_step/sec: 1.46448\n","I0720 14:11:06.929652 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46448\n","INFO:tensorflow:loss = 1.2215185, step = 3300 (68.284 sec)\n","I0720 14:11:06.931005 139770316203904 basic_session_run_hooks.py:260] loss = 1.2215185, step = 3300 (68.284 sec)\n","INFO:tensorflow:Saving checkpoints for 3378 into training/model.ckpt.\n","I0720 14:11:59.302249 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 3378 into training/model.ckpt.\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1cc2182d50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 14:12:01.681931 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1cc2182d50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1cc228aa70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 14:12:01.841775 139770316203904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1cc228aa70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0720 14:12:02.307734 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:12:04.234669 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:12:04.262645 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:12:04.289148 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:12:04.315902 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:12:04.342920 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:12:04.369129 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 14:12:06.436043 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 14:12:06.436344 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 14:12:06.436658 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 14:12:06.436910 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 14:12:06.437194 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 14:12:06.437368 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 14:12:06.437633 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 14:12:06.437802 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 14:12:06.438042 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 14:12:06.438213 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 14:12:06.438463 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 14:12:06.438628 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 14:12:06.438862 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 14:12:06.439027 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 14:12:06.439267 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 14:12:06.439442 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 14:12:06.439746 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 14:12:06.440004 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 14:12:06.440401 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 14:12:06.440685 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 14:12:06.441075 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 14:12:06.441362 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 14:12:06.441771 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 14:12:06.442058 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 14:12:06.442480 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 14:12:06.442760 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 14:12:06.443163 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 14:12:06.443459 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 14:12:06.443854 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 14:12:06.444132 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 14:12:06.444554 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 14:12:06.444789 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 14:12:06.445066 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 14:12:06.445242 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 14:12:06.445535 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 14:12:06.445732 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 14:12:06.445905 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 14:12:06.446081 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 14:12:06.446256 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 14:12:06.446439 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 14:12:06.446607 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 14:12:06.446771 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 14:12:06.446936 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I0720 14:12:07.863116 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-07-20T14:12:07Z\n","I0720 14:12:07.878071 139770316203904 evaluation.py:255] Starting evaluation at 2021-07-20T14:12:07Z\n","INFO:tensorflow:Graph was finalized.\n","I0720 14:12:08.552296 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 14:12:08.552972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:12:08.553278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 14:12:08.553364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 14:12:08.553389: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 14:12:08.553424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 14:12:08.553445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 14:12:08.553469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 14:12:08.553488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 14:12:08.553507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 14:12:08.553592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:12:08.553849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:12:08.554042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 14:12:08.554086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 14:12:08.554105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 14:12:08.554114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 14:12:08.554204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:12:08.554480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:12:08.554702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-3378\n","I0720 14:12:08.555613 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-3378\n","INFO:tensorflow:Running local_init_op.\n","I0720 14:12:10.077253 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 14:12:10.253975 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 4 images.\n","I0720 14:12:13.327497 139766408148736 coco_evaluation.py:237] Performing evaluation on 4 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0720 14:12:13.327981 139766408148736 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0720 14:12:13.328510 139766408148736 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.764\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.950\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.900\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.756\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.790\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.790\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.790\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.900\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.780\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Finished evaluation at 2021-07-20-14:12:13\n","I0720 14:12:13.808216 139770316203904 evaluation.py:275] Finished evaluation at 2021-07-20-14:12:13\n","INFO:tensorflow:Saving dict for global step 3378: DetectionBoxes_Precision/mAP = 0.76359737, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.7557756, DetectionBoxes_Precision/mAP (small) = 0.9, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 0.95049506, DetectionBoxes_Recall/AR@1 = 0.79, DetectionBoxes_Recall/AR@10 = 0.79, DetectionBoxes_Recall/AR@100 = 0.79, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.78, DetectionBoxes_Recall/AR@100 (small) = 0.9, Loss/classification_loss = 0.12806743, Loss/localization_loss = 0.11857399, Loss/regularization_loss = 0.34448847, Loss/total_loss = 0.5911299, global_step = 3378, learning_rate = 0.004, loss = 0.5911299\n","I0720 14:12:13.808496 139770316203904 estimator.py:2049] Saving dict for global step 3378: DetectionBoxes_Precision/mAP = 0.76359737, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.7557756, DetectionBoxes_Precision/mAP (small) = 0.9, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 0.95049506, DetectionBoxes_Recall/AR@1 = 0.79, DetectionBoxes_Recall/AR@10 = 0.79, DetectionBoxes_Recall/AR@100 = 0.79, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.78, DetectionBoxes_Recall/AR@100 (small) = 0.9, Loss/classification_loss = 0.12806743, Loss/localization_loss = 0.11857399, Loss/regularization_loss = 0.34448847, Loss/total_loss = 0.5911299, global_step = 3378, learning_rate = 0.004, loss = 0.5911299\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3378: training/model.ckpt-3378\n","I0720 14:12:13.810161 139770316203904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3378: training/model.ckpt-3378\n","INFO:tensorflow:global_step/sec: 1.2101\n","I0720 14:12:29.567125 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.2101\n","INFO:tensorflow:loss = 0.974244, step = 3400 (82.637 sec)\n","I0720 14:12:29.568351 139770316203904 basic_session_run_hooks.py:260] loss = 0.974244, step = 3400 (82.637 sec)\n","INFO:tensorflow:global_step/sec: 1.46543\n","I0720 14:13:37.806469 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46543\n","INFO:tensorflow:loss = 0.9679111, step = 3500 (68.239 sec)\n","I0720 14:13:37.807452 139770316203904 basic_session_run_hooks.py:260] loss = 0.9679111, step = 3500 (68.239 sec)\n","INFO:tensorflow:global_step/sec: 1.46586\n","I0720 14:14:46.025589 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46586\n","INFO:tensorflow:loss = 0.9191525, step = 3600 (68.219 sec)\n","I0720 14:14:46.026872 139770316203904 basic_session_run_hooks.py:260] loss = 0.9191525, step = 3600 (68.219 sec)\n","INFO:tensorflow:global_step/sec: 1.4622\n","I0720 14:15:54.415741 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.4622\n","INFO:tensorflow:loss = 0.86554056, step = 3700 (68.390 sec)\n","I0720 14:15:54.416717 139770316203904 basic_session_run_hooks.py:260] loss = 0.86554056, step = 3700 (68.390 sec)\n","INFO:tensorflow:global_step/sec: 1.46786\n","I0720 14:17:02.542072 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46786\n","INFO:tensorflow:loss = 1.3510852, step = 3800 (68.126 sec)\n","I0720 14:17:02.543144 139770316203904 basic_session_run_hooks.py:260] loss = 1.3510852, step = 3800 (68.126 sec)\n","INFO:tensorflow:global_step/sec: 1.46399\n","I0720 14:18:10.848486 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46399\n","INFO:tensorflow:loss = 1.0064433, step = 3900 (68.307 sec)\n","I0720 14:18:10.849874 139770316203904 basic_session_run_hooks.py:260] loss = 1.0064433, step = 3900 (68.307 sec)\n","INFO:tensorflow:global_step/sec: 1.4581\n","I0720 14:19:19.430693 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.4581\n","INFO:tensorflow:loss = 0.99919295, step = 4000 (68.582 sec)\n","I0720 14:19:19.431802 139770316203904 basic_session_run_hooks.py:260] loss = 0.99919295, step = 4000 (68.582 sec)\n","INFO:tensorflow:global_step/sec: 1.46591\n","I0720 14:20:27.647666 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46591\n","INFO:tensorflow:loss = 1.0209513, step = 4100 (68.217 sec)\n","I0720 14:20:27.648623 139770316203904 basic_session_run_hooks.py:260] loss = 1.0209513, step = 4100 (68.217 sec)\n","INFO:tensorflow:global_step/sec: 1.45638\n","I0720 14:21:36.310841 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.45638\n","INFO:tensorflow:loss = 1.3977236, step = 4200 (68.663 sec)\n","I0720 14:21:36.311900 139770316203904 basic_session_run_hooks.py:260] loss = 1.3977236, step = 4200 (68.663 sec)\n","INFO:tensorflow:Saving checkpoints for 4236 into training/model.ckpt.\n","I0720 14:21:59.893950 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 4236 into training/model.ckpt.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","W0720 14:22:00.008484 139770316203904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f19cdda61d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 14:22:02.338778 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f19cdda61d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1cc20c75f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 14:22:02.497582 139770316203904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1cc20c75f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0720 14:22:02.951693 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:22:04.860007 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:22:04.887929 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:22:04.914929 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:22:04.942702 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:22:04.970510 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:22:04.999209 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 14:22:07.145294 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 14:22:07.145614 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 14:22:07.145887 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 14:22:07.146077 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 14:22:07.146331 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 14:22:07.146509 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 14:22:07.146892 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 14:22:07.147177 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 14:22:07.147458 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 14:22:07.147649 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 14:22:07.147910 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 14:22:07.148085 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 14:22:07.148332 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 14:22:07.148512 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 14:22:07.148778 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 14:22:07.148950 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 14:22:07.149192 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 14:22:07.149361 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 14:22:07.149631 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 14:22:07.149805 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 14:22:07.150047 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 14:22:07.150217 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 14:22:07.150470 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 14:22:07.150649 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 14:22:07.150899 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 14:22:07.151068 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 14:22:07.151309 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 14:22:07.151488 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 14:22:07.151743 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 14:22:07.151918 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 14:22:07.152159 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 14:22:07.152326 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 14:22:07.152585 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 14:22:07.152765 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 14:22:07.153014 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 14:22:07.153178 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 14:22:07.153342 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 14:22:07.153519 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 14:22:07.153697 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 14:22:07.153866 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 14:22:07.154033 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 14:22:07.154200 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 14:22:07.154366 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I0720 14:22:08.002346 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-07-20T14:22:08Z\n","I0720 14:22:08.017200 139770316203904 evaluation.py:255] Starting evaluation at 2021-07-20T14:22:08Z\n","INFO:tensorflow:Graph was finalized.\n","I0720 14:22:08.708472 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 14:22:08.709140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:22:08.709457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 14:22:08.709548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 14:22:08.709572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 14:22:08.709601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 14:22:08.709621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 14:22:08.709640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 14:22:08.709659: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 14:22:08.709678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 14:22:08.709763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:22:08.710018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:22:08.710220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 14:22:08.710301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 14:22:08.710315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 14:22:08.710324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 14:22:08.710428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:22:08.710682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:22:08.710886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-4236\n","I0720 14:22:08.711822 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-4236\n","INFO:tensorflow:Running local_init_op.\n","I0720 14:22:10.170143 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 14:22:10.344514 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 4 images.\n","I0720 14:22:13.393049 139766416541440 coco_evaluation.py:237] Performing evaluation on 4 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0720 14:22:13.393411 139766416541440 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0720 14:22:13.394100 139766416541440 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.759\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.758\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.780\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.780\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.780\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.778\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Finished evaluation at 2021-07-20-14:22:13\n","I0720 14:22:13.924124 139770316203904 evaluation.py:275] Finished evaluation at 2021-07-20-14:22:13\n","INFO:tensorflow:Saving dict for global step 4236: DetectionBoxes_Precision/mAP = 0.7594059, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.7579208, DetectionBoxes_Precision/mAP (small) = 0.8, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.78, DetectionBoxes_Recall/AR@10 = 0.78, DetectionBoxes_Recall/AR@100 = 0.78, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.7783333, DetectionBoxes_Recall/AR@100 (small) = 0.8, Loss/classification_loss = 0.14255774, Loss/localization_loss = 0.17078012, Loss/regularization_loss = 0.34372452, Loss/total_loss = 0.6570624, global_step = 4236, learning_rate = 0.004, loss = 0.6570624\n","I0720 14:22:13.924468 139770316203904 estimator.py:2049] Saving dict for global step 4236: DetectionBoxes_Precision/mAP = 0.7594059, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.7579208, DetectionBoxes_Precision/mAP (small) = 0.8, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.78, DetectionBoxes_Recall/AR@10 = 0.78, DetectionBoxes_Recall/AR@100 = 0.78, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.7783333, DetectionBoxes_Recall/AR@100 (small) = 0.8, Loss/classification_loss = 0.14255774, Loss/localization_loss = 0.17078012, Loss/regularization_loss = 0.34372452, Loss/total_loss = 0.6570624, global_step = 4236, learning_rate = 0.004, loss = 0.6570624\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4236: training/model.ckpt-4236\n","I0720 14:22:13.926461 139770316203904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4236: training/model.ckpt-4236\n","INFO:tensorflow:global_step/sec: 1.22027\n","I0720 14:22:58.259925 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.22027\n","INFO:tensorflow:loss = 0.9986867, step = 4300 (81.949 sec)\n","I0720 14:22:58.261100 139770316203904 basic_session_run_hooks.py:260] loss = 0.9986867, step = 4300 (81.949 sec)\n","INFO:tensorflow:global_step/sec: 1.46708\n","I0720 14:24:06.422457 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46708\n","INFO:tensorflow:loss = 1.3009193, step = 4400 (68.163 sec)\n","I0720 14:24:06.423655 139770316203904 basic_session_run_hooks.py:260] loss = 1.3009193, step = 4400 (68.163 sec)\n","INFO:tensorflow:global_step/sec: 1.46251\n","I0720 14:25:14.798095 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46251\n","INFO:tensorflow:loss = 1.4521792, step = 4500 (68.376 sec)\n","I0720 14:25:14.799320 139770316203904 basic_session_run_hooks.py:260] loss = 1.4521792, step = 4500 (68.376 sec)\n","INFO:tensorflow:global_step/sec: 1.45628\n","I0720 14:26:23.466168 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.45628\n","INFO:tensorflow:loss = 1.0160997, step = 4600 (68.668 sec)\n","I0720 14:26:23.467255 139770316203904 basic_session_run_hooks.py:260] loss = 1.0160997, step = 4600 (68.668 sec)\n","INFO:tensorflow:global_step/sec: 1.46767\n","I0720 14:27:31.601454 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46767\n","INFO:tensorflow:loss = 0.9233291, step = 4700 (68.135 sec)\n","I0720 14:27:31.602644 139770316203904 basic_session_run_hooks.py:260] loss = 0.9233291, step = 4700 (68.135 sec)\n","INFO:tensorflow:global_step/sec: 1.46973\n","I0720 14:28:39.640984 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46973\n","INFO:tensorflow:loss = 1.1720248, step = 4800 (68.040 sec)\n","I0720 14:28:39.642370 139770316203904 basic_session_run_hooks.py:260] loss = 1.1720248, step = 4800 (68.040 sec)\n","INFO:tensorflow:global_step/sec: 1.46281\n","I0720 14:29:48.002713 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46281\n","INFO:tensorflow:loss = 1.1018437, step = 4900 (68.362 sec)\n","I0720 14:29:48.003913 139770316203904 basic_session_run_hooks.py:260] loss = 1.1018437, step = 4900 (68.362 sec)\n","INFO:tensorflow:global_step/sec: 1.46824\n","I0720 14:30:56.111664 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46824\n","INFO:tensorflow:loss = 0.9884473, step = 5000 (68.109 sec)\n","I0720 14:30:56.112928 139770316203904 basic_session_run_hooks.py:260] loss = 0.9884473, step = 5000 (68.109 sec)\n","INFO:tensorflow:Saving checkpoints for 5095 into training/model.ckpt.\n","I0720 14:32:00.108105 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 5095 into training/model.ckpt.\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1cc2243ad0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 14:32:02.501001 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1cc2243ad0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1cc2725050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 14:32:02.663967 139770316203904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1cc2725050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0720 14:32:03.127854 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:32:05.054329 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:32:05.081701 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:32:05.108203 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:32:05.135478 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:32:05.162767 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:32:05.190141 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 14:32:07.824753 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 14:32:07.825139 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 14:32:07.825474 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 14:32:07.825699 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 14:32:07.826002 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 14:32:07.826218 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 14:32:07.826529 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 14:32:07.826742 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 14:32:07.827042 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 14:32:07.827247 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 14:32:07.827552 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 14:32:07.827764 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 14:32:07.828056 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 14:32:07.828262 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 14:32:07.828563 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 14:32:07.828771 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 14:32:07.829052 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 14:32:07.829249 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 14:32:07.829545 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 14:32:07.829747 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 14:32:07.830033 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 14:32:07.830231 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 14:32:07.830526 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 14:32:07.830729 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 14:32:07.831017 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 14:32:07.831213 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 14:32:07.831507 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 14:32:07.831711 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 14:32:07.831997 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 14:32:07.832191 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 14:32:07.832493 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 14:32:07.832719 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 14:32:07.833046 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 14:32:07.833257 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 14:32:07.833561 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 14:32:07.833792 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 14:32:07.833996 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 14:32:07.834213 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 14:32:07.834426 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 14:32:07.834629 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 14:32:07.834825 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 14:32:07.835031 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 14:32:07.835228 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I0720 14:32:08.767510 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-07-20T14:32:08Z\n","I0720 14:32:08.785872 139770316203904 evaluation.py:255] Starting evaluation at 2021-07-20T14:32:08Z\n","INFO:tensorflow:Graph was finalized.\n","I0720 14:32:09.514544 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 14:32:09.515280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:32:09.515657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 14:32:09.515764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 14:32:09.515804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 14:32:09.515833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 14:32:09.515867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 14:32:09.515888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 14:32:09.515913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 14:32:09.515939: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 14:32:09.516039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:32:09.516310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:32:09.516514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 14:32:09.516558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 14:32:09.516571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 14:32:09.516587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 14:32:09.516683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:32:09.516932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:32:09.517141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-5095\n","I0720 14:32:09.518496 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-5095\n","INFO:tensorflow:Running local_init_op.\n","I0720 14:32:11.159143 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 14:32:11.352887 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 4 images.\n","I0720 14:32:14.602803 139766416541440 coco_evaluation.py:237] Performing evaluation on 4 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0720 14:32:14.603205 139766416541440 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0720 14:32:14.603837 139766416541440 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.05s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.793\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.900\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.792\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.815\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.815\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.815\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.900\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.812\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Finished evaluation at 2021-07-20-14:32:15\n","I0720 14:32:15.140009 139770316203904 evaluation.py:275] Finished evaluation at 2021-07-20-14:32:15\n","INFO:tensorflow:Saving dict for global step 5095: DetectionBoxes_Precision/mAP = 0.79330033, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.79161716, DetectionBoxes_Precision/mAP (small) = 0.9, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.815, DetectionBoxes_Recall/AR@10 = 0.815, DetectionBoxes_Recall/AR@100 = 0.815, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.81166667, DetectionBoxes_Recall/AR@100 (small) = 0.9, Loss/classification_loss = 0.06606848, Loss/localization_loss = 0.11955588, Loss/regularization_loss = 0.34295177, Loss/total_loss = 0.52857614, global_step = 5095, learning_rate = 0.004, loss = 0.52857614\n","I0720 14:32:15.140277 139770316203904 estimator.py:2049] Saving dict for global step 5095: DetectionBoxes_Precision/mAP = 0.79330033, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.79161716, DetectionBoxes_Precision/mAP (small) = 0.9, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.815, DetectionBoxes_Recall/AR@10 = 0.815, DetectionBoxes_Recall/AR@100 = 0.815, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.81166667, DetectionBoxes_Recall/AR@100 (small) = 0.9, Loss/classification_loss = 0.06606848, Loss/localization_loss = 0.11955588, Loss/regularization_loss = 0.34295177, Loss/total_loss = 0.52857614, global_step = 5095, learning_rate = 0.004, loss = 0.52857614\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5095: training/model.ckpt-5095\n","I0720 14:32:15.142071 139770316203904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5095: training/model.ckpt-5095\n","INFO:tensorflow:global_step/sec: 1.20171\n","I0720 14:32:19.326342 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.20171\n","INFO:tensorflow:loss = 1.1251674, step = 5100 (83.215 sec)\n","I0720 14:32:19.327473 139770316203904 basic_session_run_hooks.py:260] loss = 1.1251674, step = 5100 (83.215 sec)\n","INFO:tensorflow:global_step/sec: 1.46295\n","I0720 14:33:27.681335 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46295\n","INFO:tensorflow:loss = 1.0148972, step = 5200 (68.355 sec)\n","I0720 14:33:27.682458 139770316203904 basic_session_run_hooks.py:260] loss = 1.0148972, step = 5200 (68.355 sec)\n","INFO:tensorflow:global_step/sec: 1.46746\n","I0720 14:34:35.826097 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46746\n","INFO:tensorflow:loss = 1.0409857, step = 5300 (68.145 sec)\n","I0720 14:34:35.827460 139770316203904 basic_session_run_hooks.py:260] loss = 1.0409857, step = 5300 (68.145 sec)\n","INFO:tensorflow:global_step/sec: 1.46733\n","I0720 14:35:43.976974 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46733\n","INFO:tensorflow:loss = 1.0642915, step = 5400 (68.151 sec)\n","I0720 14:35:43.978250 139770316203904 basic_session_run_hooks.py:260] loss = 1.0642915, step = 5400 (68.151 sec)\n","INFO:tensorflow:global_step/sec: 1.46603\n","I0720 14:36:52.188452 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46603\n","INFO:tensorflow:loss = 1.0311825, step = 5500 (68.212 sec)\n","I0720 14:36:52.189782 139770316203904 basic_session_run_hooks.py:260] loss = 1.0311825, step = 5500 (68.212 sec)\n","INFO:tensorflow:global_step/sec: 1.46503\n","I0720 14:38:00.446283 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46503\n","INFO:tensorflow:loss = 0.94117403, step = 5600 (68.258 sec)\n","I0720 14:38:00.447534 139770316203904 basic_session_run_hooks.py:260] loss = 0.94117403, step = 5600 (68.258 sec)\n","INFO:tensorflow:global_step/sec: 1.46672\n","I0720 14:39:08.625625 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46672\n","INFO:tensorflow:loss = 1.0200586, step = 5700 (68.179 sec)\n","I0720 14:39:08.626631 139770316203904 basic_session_run_hooks.py:260] loss = 1.0200586, step = 5700 (68.179 sec)\n","INFO:tensorflow:global_step/sec: 1.46498\n","I0720 14:40:16.885958 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46498\n","INFO:tensorflow:loss = 1.2397497, step = 5800 (68.260 sec)\n","I0720 14:40:16.887123 139770316203904 basic_session_run_hooks.py:260] loss = 1.2397497, step = 5800 (68.260 sec)\n","INFO:tensorflow:global_step/sec: 1.47015\n","I0720 14:41:24.906386 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.47015\n","INFO:tensorflow:loss = 0.88945055, step = 5900 (68.020 sec)\n","I0720 14:41:24.907483 139770316203904 basic_session_run_hooks.py:260] loss = 0.88945055, step = 5900 (68.020 sec)\n","INFO:tensorflow:Saving checkpoints for 5953 into training/model.ckpt.\n","I0720 14:42:00.453167 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 5953 into training/model.ckpt.\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f19cdd26810>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 14:42:02.898004 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f19cdd26810>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1e40131c20> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 14:42:03.057919 139770316203904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1e40131c20> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0720 14:42:03.520977 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:42:05.443531 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:42:05.470989 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:42:05.497773 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:42:05.524468 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:42:05.550793 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:42:05.577210 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 14:42:07.616572 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 14:42:07.616924 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 14:42:07.617203 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 14:42:07.617399 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 14:42:07.617671 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 14:42:07.617852 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 14:42:07.618109 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 14:42:07.618286 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 14:42:07.618552 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 14:42:07.618741 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 14:42:07.618998 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 14:42:07.619176 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 14:42:07.619438 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 14:42:07.619636 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 14:42:07.619894 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 14:42:07.620068 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 14:42:07.620321 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 14:42:07.620504 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 14:42:07.620766 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 14:42:07.620940 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 14:42:07.621191 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 14:42:07.621362 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 14:42:07.621656 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 14:42:07.621838 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 14:42:07.622091 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 14:42:07.622266 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 14:42:07.622532 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 14:42:07.622717 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 14:42:07.622966 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 14:42:07.623136 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 14:42:07.623387 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 14:42:07.623568 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 14:42:07.623825 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 14:42:07.624004 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 14:42:07.624272 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 14:42:07.624451 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 14:42:07.624625 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 14:42:07.624799 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 14:42:07.624979 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 14:42:07.625168 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 14:42:07.625358 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 14:42:07.625561 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 14:42:07.625755 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I0720 14:42:08.495799 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-07-20T14:42:08Z\n","I0720 14:42:08.512675 139770316203904 evaluation.py:255] Starting evaluation at 2021-07-20T14:42:08Z\n","INFO:tensorflow:Graph was finalized.\n","I0720 14:42:09.260433 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 14:42:09.261140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:42:09.261475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 14:42:09.261570: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 14:42:09.261608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 14:42:09.261639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 14:42:09.261661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 14:42:09.261681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 14:42:09.261701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 14:42:09.261722: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 14:42:09.261822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:42:09.262095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:42:09.262298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 14:42:09.262383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 14:42:09.262406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 14:42:09.262416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 14:42:09.262512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:42:09.262778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:42:09.262992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-5953\n","I0720 14:42:09.263928 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-5953\n","INFO:tensorflow:Running local_init_op.\n","I0720 14:42:10.730585 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 14:42:10.899053 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 4 images.\n","I0720 14:42:14.002487 139766416541440 coco_evaluation.py:237] Performing evaluation on 4 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0720 14:42:14.002997 139766416541440 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0720 14:42:14.003615 139766416541440 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.778\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.815\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.815\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.815\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.813\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Finished evaluation at 2021-07-20-14:42:14\n","I0720 14:42:14.498612 139770316203904 evaluation.py:275] Finished evaluation at 2021-07-20-14:42:14\n","INFO:tensorflow:Saving dict for global step 5953: DetectionBoxes_Precision/mAP = 0.78089106, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.77755773, DetectionBoxes_Precision/mAP (small) = 0.8, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.815, DetectionBoxes_Recall/AR@10 = 0.815, DetectionBoxes_Recall/AR@100 = 0.815, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.81333333, DetectionBoxes_Recall/AR@100 (small) = 0.8, Loss/classification_loss = 0.0943662, Loss/localization_loss = 0.1270441, Loss/regularization_loss = 0.342169, Loss/total_loss = 0.56357926, global_step = 5953, learning_rate = 0.004, loss = 0.56357926\n","I0720 14:42:14.498905 139770316203904 estimator.py:2049] Saving dict for global step 5953: DetectionBoxes_Precision/mAP = 0.78089106, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.77755773, DetectionBoxes_Precision/mAP (small) = 0.8, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.815, DetectionBoxes_Recall/AR@10 = 0.815, DetectionBoxes_Recall/AR@100 = 0.815, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.81333333, DetectionBoxes_Recall/AR@100 (small) = 0.8, Loss/classification_loss = 0.0943662, Loss/localization_loss = 0.1270441, Loss/regularization_loss = 0.342169, Loss/total_loss = 0.56357926, global_step = 5953, learning_rate = 0.004, loss = 0.56357926\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5953: training/model.ckpt-5953\n","I0720 14:42:14.500727 139770316203904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5953: training/model.ckpt-5953\n","INFO:tensorflow:global_step/sec: 1.21304\n","I0720 14:42:47.343610 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.21304\n","INFO:tensorflow:loss = 1.2359183, step = 6000 (82.437 sec)\n","I0720 14:42:47.344781 139770316203904 basic_session_run_hooks.py:260] loss = 1.2359183, step = 6000 (82.437 sec)\n","INFO:tensorflow:global_step/sec: 1.46082\n","I0720 14:43:55.798420 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46082\n","INFO:tensorflow:loss = 1.0345188, step = 6100 (68.455 sec)\n","I0720 14:43:55.799628 139770316203904 basic_session_run_hooks.py:260] loss = 1.0345188, step = 6100 (68.455 sec)\n","INFO:tensorflow:global_step/sec: 1.46614\n","I0720 14:45:04.004782 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46614\n","INFO:tensorflow:loss = 1.1977882, step = 6200 (68.206 sec)\n","I0720 14:45:04.006033 139770316203904 basic_session_run_hooks.py:260] loss = 1.1977882, step = 6200 (68.206 sec)\n","INFO:tensorflow:global_step/sec: 1.46748\n","I0720 14:46:12.148844 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46748\n","INFO:tensorflow:loss = 1.1689769, step = 6300 (68.144 sec)\n","I0720 14:46:12.149927 139770316203904 basic_session_run_hooks.py:260] loss = 1.1689769, step = 6300 (68.144 sec)\n","INFO:tensorflow:global_step/sec: 1.46449\n","I0720 14:47:20.432125 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46449\n","INFO:tensorflow:loss = 1.1449026, step = 6400 (68.283 sec)\n","I0720 14:47:20.433314 139770316203904 basic_session_run_hooks.py:260] loss = 1.1449026, step = 6400 (68.283 sec)\n","INFO:tensorflow:global_step/sec: 1.45804\n","I0720 14:48:29.017430 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.45804\n","INFO:tensorflow:loss = 1.0717899, step = 6500 (68.585 sec)\n","I0720 14:48:29.018687 139770316203904 basic_session_run_hooks.py:260] loss = 1.0717899, step = 6500 (68.585 sec)\n","INFO:tensorflow:global_step/sec: 1.46292\n","I0720 14:49:37.373785 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46292\n","INFO:tensorflow:loss = 0.9664209, step = 6600 (68.356 sec)\n","I0720 14:49:37.375040 139770316203904 basic_session_run_hooks.py:260] loss = 0.9664209, step = 6600 (68.356 sec)\n","INFO:tensorflow:global_step/sec: 1.46588\n","I0720 14:50:45.591997 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46588\n","INFO:tensorflow:loss = 0.944494, step = 6700 (68.218 sec)\n","I0720 14:50:45.593031 139770316203904 basic_session_run_hooks.py:260] loss = 0.944494, step = 6700 (68.218 sec)\n","INFO:tensorflow:global_step/sec: 1.4648\n","I0720 14:51:53.860661 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.4648\n","INFO:tensorflow:loss = 1.1089008, step = 6800 (68.269 sec)\n","I0720 14:51:53.861883 139770316203904 basic_session_run_hooks.py:260] loss = 1.1089008, step = 6800 (68.269 sec)\n","INFO:tensorflow:Saving checkpoints for 6811 into training/model.ckpt.\n","I0720 14:52:00.640706 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 6811 into training/model.ckpt.\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1cc2fef110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 14:52:03.083843 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1cc2fef110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1de034b3b0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 14:52:03.242061 139770316203904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1de034b3b0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0720 14:52:03.689307 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:52:05.620526 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:52:05.649531 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:52:05.677844 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:52:05.706043 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:52:05.733927 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 14:52:05.761321 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 14:52:08.414088 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 14:52:08.414401 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 14:52:08.414678 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 14:52:08.414855 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 14:52:08.415098 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 14:52:08.415266 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 14:52:08.415514 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 14:52:08.415688 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 14:52:08.415925 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 14:52:08.416096 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 14:52:08.416340 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 14:52:08.416514 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 14:52:08.416757 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 14:52:08.416923 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 14:52:08.417160 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 14:52:08.417327 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 14:52:08.417572 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 14:52:08.417747 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 14:52:08.417983 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 14:52:08.418158 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 14:52:08.418422 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 14:52:08.418595 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 14:52:08.418833 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 14:52:08.419006 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 14:52:08.419251 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 14:52:08.419422 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 14:52:08.419705 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 14:52:08.419899 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 14:52:08.420173 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 14:52:08.420360 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 14:52:08.420657 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 14:52:08.420843 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 14:52:08.421085 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 14:52:08.421241 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 14:52:08.421539 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 14:52:08.421732 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 14:52:08.421897 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 14:52:08.422060 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 14:52:08.422220 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 14:52:08.422405 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 14:52:08.422586 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 14:52:08.422749 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 14:52:08.422909 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I0720 14:52:09.289422 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-07-20T14:52:09Z\n","I0720 14:52:09.304774 139770316203904 evaluation.py:255] Starting evaluation at 2021-07-20T14:52:09Z\n","INFO:tensorflow:Graph was finalized.\n","I0720 14:52:10.005265 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 14:52:10.005901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:52:10.006202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 14:52:10.006296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 14:52:10.006326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 14:52:10.006348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 14:52:10.006371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 14:52:10.006404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 14:52:10.006424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 14:52:10.006444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 14:52:10.006527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:52:10.006787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:52:10.006981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 14:52:10.007024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 14:52:10.007037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 14:52:10.007047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 14:52:10.007146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:52:10.007410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 14:52:10.007617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-6811\n","I0720 14:52:10.008576 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-6811\n","INFO:tensorflow:Running local_init_op.\n","I0720 14:52:11.673815 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 14:52:11.889929 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 4 images.\n","I0720 14:52:14.899078 139766408148736 coco_evaluation.py:237] Performing evaluation on 4 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0720 14:52:14.899532 139766408148736 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0720 14:52:14.900174 139766408148736 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.804\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.814\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.815\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.815\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.815\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.825\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Finished evaluation at 2021-07-20-14:52:15\n","I0720 14:52:15.401363 139770316203904 evaluation.py:275] Finished evaluation at 2021-07-20-14:52:15\n","INFO:tensorflow:Saving dict for global step 6811: DetectionBoxes_Precision/mAP = 0.8039934, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.8138944, DetectionBoxes_Precision/mAP (small) = 0.7, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.815, DetectionBoxes_Recall/AR@10 = 0.815, DetectionBoxes_Recall/AR@100 = 0.815, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.825, DetectionBoxes_Recall/AR@100 (small) = 0.7, Loss/classification_loss = 0.047705535, Loss/localization_loss = 0.12721613, Loss/regularization_loss = 0.34138456, Loss/total_loss = 0.5163062, global_step = 6811, learning_rate = 0.004, loss = 0.5163062\n","I0720 14:52:15.401687 139770316203904 estimator.py:2049] Saving dict for global step 6811: DetectionBoxes_Precision/mAP = 0.8039934, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.8138944, DetectionBoxes_Precision/mAP (small) = 0.7, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.815, DetectionBoxes_Recall/AR@10 = 0.815, DetectionBoxes_Recall/AR@100 = 0.815, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.825, DetectionBoxes_Recall/AR@100 (small) = 0.7, Loss/classification_loss = 0.047705535, Loss/localization_loss = 0.12721613, Loss/regularization_loss = 0.34138456, Loss/total_loss = 0.5163062, global_step = 6811, learning_rate = 0.004, loss = 0.5163062\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6811: training/model.ckpt-6811\n","I0720 14:52:15.403414 139770316203904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 6811: training/model.ckpt-6811\n","INFO:tensorflow:global_step/sec: 1.199\n","I0720 14:53:17.263708 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.199\n","INFO:tensorflow:loss = 1.1861739, step = 6900 (83.403 sec)\n","I0720 14:53:17.264926 139770316203904 basic_session_run_hooks.py:260] loss = 1.1861739, step = 6900 (83.403 sec)\n","INFO:tensorflow:global_step/sec: 1.46551\n","I0720 14:54:25.499554 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46551\n","INFO:tensorflow:loss = 1.1576858, step = 7000 (68.236 sec)\n","I0720 14:54:25.501253 139770316203904 basic_session_run_hooks.py:260] loss = 1.1576858, step = 7000 (68.236 sec)\n","INFO:tensorflow:global_step/sec: 1.46518\n","I0720 14:55:33.750572 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46518\n","INFO:tensorflow:loss = 1.1403861, step = 7100 (68.251 sec)\n","I0720 14:55:33.752052 139770316203904 basic_session_run_hooks.py:260] loss = 1.1403861, step = 7100 (68.251 sec)\n","INFO:tensorflow:global_step/sec: 1.46445\n","I0720 14:56:42.035746 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46445\n","INFO:tensorflow:loss = 1.0462029, step = 7200 (68.285 sec)\n","I0720 14:56:42.036998 139770316203904 basic_session_run_hooks.py:260] loss = 1.0462029, step = 7200 (68.285 sec)\n","INFO:tensorflow:global_step/sec: 1.46507\n","I0720 14:57:50.291963 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46507\n","INFO:tensorflow:loss = 1.0788884, step = 7300 (68.256 sec)\n","I0720 14:57:50.293301 139770316203904 basic_session_run_hooks.py:260] loss = 1.0788884, step = 7300 (68.256 sec)\n","INFO:tensorflow:global_step/sec: 1.4633\n","I0720 14:58:58.630434 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.4633\n","INFO:tensorflow:loss = 0.9904823, step = 7400 (68.338 sec)\n","I0720 14:58:58.631556 139770316203904 basic_session_run_hooks.py:260] loss = 0.9904823, step = 7400 (68.338 sec)\n","INFO:tensorflow:global_step/sec: 1.4671\n","I0720 15:00:06.791942 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.4671\n","INFO:tensorflow:loss = 1.0200193, step = 7500 (68.162 sec)\n","I0720 15:00:06.793187 139770316203904 basic_session_run_hooks.py:260] loss = 1.0200193, step = 7500 (68.162 sec)\n","INFO:tensorflow:global_step/sec: 1.46271\n","I0720 15:01:15.158333 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46271\n","INFO:tensorflow:loss = 1.0601714, step = 7600 (68.367 sec)\n","I0720 15:01:15.159797 139770316203904 basic_session_run_hooks.py:260] loss = 1.0601714, step = 7600 (68.367 sec)\n","INFO:tensorflow:Saving checkpoints for 7668 into training/model.ckpt.\n","I0720 15:02:01.110029 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 7668 into training/model.ckpt.\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1cc29e1110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 15:02:03.527129 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1cc29e1110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1cc2154c20> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 15:02:03.689410 139770316203904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1cc2154c20> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0720 15:02:04.143682 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:02:06.037033 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:02:06.065626 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:02:06.096263 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:02:06.124043 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:02:06.151465 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:02:06.178503 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 15:02:08.266023 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 15:02:08.266377 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 15:02:08.266688 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 15:02:08.266884 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 15:02:08.267151 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 15:02:08.267334 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 15:02:08.267607 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 15:02:08.267794 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 15:02:08.268055 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 15:02:08.268237 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 15:02:08.268507 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 15:02:08.268693 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 15:02:08.268955 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 15:02:08.269135 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 15:02:08.269390 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 15:02:08.269577 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 15:02:08.269841 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 15:02:08.270019 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 15:02:08.270271 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 15:02:08.270456 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 15:02:08.270720 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 15:02:08.270901 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 15:02:08.271158 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 15:02:08.271336 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 15:02:08.271606 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 15:02:08.271787 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 15:02:08.272042 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 15:02:08.272216 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 15:02:08.272483 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 15:02:08.272671 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 15:02:08.272929 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 15:02:08.273104 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 15:02:08.273358 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 15:02:08.273541 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 15:02:08.273828 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 15:02:08.274001 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 15:02:08.274175 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 15:02:08.274349 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 15:02:08.274535 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 15:02:08.274740 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 15:02:08.274923 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 15:02:08.275098 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 15:02:08.275272 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I0720 15:02:09.143806 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-07-20T15:02:09Z\n","I0720 15:02:09.159226 139770316203904 evaluation.py:255] Starting evaluation at 2021-07-20T15:02:09Z\n","INFO:tensorflow:Graph was finalized.\n","I0720 15:02:09.855229 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 15:02:09.855948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:02:09.856251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:02:09.856351: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:02:09.856381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:02:09.856424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:02:09.856451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:02:09.856473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:02:09.856493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:02:09.856513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:02:09.856602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:02:09.856882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:02:09.857086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:02:09.857175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 15:02:09.857190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 15:02:09.857200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 15:02:09.857299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:02:09.857567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:02:09.857780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-7668\n","I0720 15:02:09.858739 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-7668\n","INFO:tensorflow:Running local_init_op.\n","I0720 15:02:11.342453 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 15:02:11.508443 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 4 images.\n","I0720 15:02:14.533253 139766408148736 coco_evaluation.py:237] Performing evaluation on 4 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0720 15:02:14.534277 139766408148736 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0720 15:02:14.534714 139766408148736 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.817\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.819\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.820\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.820\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.820\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.823\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Finished evaluation at 2021-07-20-15:02:15\n","I0720 15:02:15.042370 139770316203904 evaluation.py:275] Finished evaluation at 2021-07-20-15:02:15\n","INFO:tensorflow:Saving dict for global step 7668: DetectionBoxes_Precision/mAP = 0.8170297, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.8191419, DetectionBoxes_Precision/mAP (small) = 0.8, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.82, DetectionBoxes_Recall/AR@10 = 0.82, DetectionBoxes_Recall/AR@100 = 0.82, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.8233333, DetectionBoxes_Recall/AR@100 (small) = 0.8, Loss/classification_loss = 0.045554742, Loss/localization_loss = 0.09881812, Loss/regularization_loss = 0.34059665, Loss/total_loss = 0.4849695, global_step = 7668, learning_rate = 0.004, loss = 0.4849695\n","I0720 15:02:15.042676 139770316203904 estimator.py:2049] Saving dict for global step 7668: DetectionBoxes_Precision/mAP = 0.8170297, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.8191419, DetectionBoxes_Precision/mAP (small) = 0.8, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.82, DetectionBoxes_Recall/AR@10 = 0.82, DetectionBoxes_Recall/AR@100 = 0.82, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.8233333, DetectionBoxes_Recall/AR@100 (small) = 0.8, Loss/classification_loss = 0.045554742, Loss/localization_loss = 0.09881812, Loss/regularization_loss = 0.34059665, Loss/total_loss = 0.4849695, global_step = 7668, learning_rate = 0.004, loss = 0.4849695\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7668: training/model.ckpt-7668\n","I0720 15:02:15.044427 139770316203904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 7668: training/model.ckpt-7668\n","INFO:tensorflow:global_step/sec: 1.21173\n","I0720 15:02:37.684949 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.21173\n","INFO:tensorflow:loss = 0.9088454, step = 7700 (82.526 sec)\n","I0720 15:02:37.686262 139770316203904 basic_session_run_hooks.py:260] loss = 0.9088454, step = 7700 (82.526 sec)\n","INFO:tensorflow:global_step/sec: 1.46837\n","I0720 15:03:45.787737 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46837\n","INFO:tensorflow:loss = 0.89889795, step = 7800 (68.104 sec)\n","I0720 15:03:45.790151 139770316203904 basic_session_run_hooks.py:260] loss = 0.89889795, step = 7800 (68.104 sec)\n","INFO:tensorflow:global_step/sec: 1.45756\n","I0720 15:04:54.395720 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.45756\n","INFO:tensorflow:loss = 1.0282829, step = 7900 (68.607 sec)\n","I0720 15:04:54.396833 139770316203904 basic_session_run_hooks.py:260] loss = 1.0282829, step = 7900 (68.607 sec)\n","INFO:tensorflow:global_step/sec: 1.46449\n","I0720 15:06:02.678667 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46449\n","INFO:tensorflow:loss = 1.0749314, step = 8000 (68.283 sec)\n","I0720 15:06:02.679553 139770316203904 basic_session_run_hooks.py:260] loss = 1.0749314, step = 8000 (68.283 sec)\n","INFO:tensorflow:global_step/sec: 1.46472\n","I0720 15:07:10.951236 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46472\n","INFO:tensorflow:loss = 1.0547962, step = 8100 (68.273 sec)\n","I0720 15:07:10.952657 139770316203904 basic_session_run_hooks.py:260] loss = 1.0547962, step = 8100 (68.273 sec)\n","INFO:tensorflow:global_step/sec: 1.47086\n","I0720 15:08:18.938504 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.47086\n","INFO:tensorflow:loss = 0.8558029, step = 8200 (67.987 sec)\n","I0720 15:08:18.939670 139770316203904 basic_session_run_hooks.py:260] loss = 0.8558029, step = 8200 (67.987 sec)\n","INFO:tensorflow:global_step/sec: 1.47199\n","I0720 15:09:26.873710 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.47199\n","INFO:tensorflow:loss = 1.0539954, step = 8300 (67.935 sec)\n","I0720 15:09:26.874938 139770316203904 basic_session_run_hooks.py:260] loss = 1.0539954, step = 8300 (67.935 sec)\n","INFO:tensorflow:global_step/sec: 1.46085\n","I0720 15:10:35.326947 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46085\n","INFO:tensorflow:loss = 0.92054754, step = 8400 (68.453 sec)\n","I0720 15:10:35.328126 139770316203904 basic_session_run_hooks.py:260] loss = 0.92054754, step = 8400 (68.453 sec)\n","INFO:tensorflow:global_step/sec: 1.46752\n","I0720 15:11:43.468994 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46752\n","INFO:tensorflow:loss = 1.0391968, step = 8500 (68.142 sec)\n","I0720 15:11:43.470220 139770316203904 basic_session_run_hooks.py:260] loss = 1.0391968, step = 8500 (68.142 sec)\n","INFO:tensorflow:Saving checkpoints for 8528 into training/model.ckpt.\n","I0720 15:12:01.604846 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 8528 into training/model.ckpt.\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f19cb7e3a90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 15:12:04.019950 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f19cb7e3a90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f19cb7e0050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 15:12:04.179093 139770316203904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f19cb7e0050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0720 15:12:04.638621 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:12:06.543625 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:12:06.570703 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:12:06.598524 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:12:06.625765 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:12:06.652039 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:12:06.678535 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 15:12:09.304585 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 15:12:09.304893 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 15:12:09.305167 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 15:12:09.305348 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 15:12:09.305616 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 15:12:09.305795 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 15:12:09.306039 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 15:12:09.306218 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 15:12:09.306471 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 15:12:09.306647 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 15:12:09.306890 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 15:12:09.307060 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 15:12:09.307298 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 15:12:09.307475 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 15:12:09.307730 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 15:12:09.307898 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 15:12:09.308140 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 15:12:09.308309 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 15:12:09.308557 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 15:12:09.308734 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 15:12:09.308975 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 15:12:09.309144 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 15:12:09.309384 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 15:12:09.309559 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 15:12:09.309807 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 15:12:09.309975 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 15:12:09.310215 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 15:12:09.310381 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 15:12:09.310644 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 15:12:09.310812 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 15:12:09.311049 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 15:12:09.311216 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 15:12:09.311468 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 15:12:09.311643 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 15:12:09.311886 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 15:12:09.312046 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 15:12:09.312205 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 15:12:09.312371 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 15:12:09.312555 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 15:12:09.312731 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 15:12:09.312899 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 15:12:09.313068 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 15:12:09.313235 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I0720 15:12:10.163461 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-07-20T15:12:10Z\n","I0720 15:12:10.178624 139770316203904 evaluation.py:255] Starting evaluation at 2021-07-20T15:12:10Z\n","INFO:tensorflow:Graph was finalized.\n","I0720 15:12:10.863750 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 15:12:10.864462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:12:10.864765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:12:10.864864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:12:10.864889: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:12:10.864914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:12:10.864935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:12:10.864956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:12:10.864977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:12:10.865000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:12:10.865085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:12:10.865344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:12:10.865596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:12:10.865641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 15:12:10.865655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 15:12:10.865664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 15:12:10.865766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:12:10.866018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:12:10.866222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-8528\n","I0720 15:12:10.867336 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-8528\n","INFO:tensorflow:Running local_init_op.\n","I0720 15:12:12.398422 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 15:12:12.596839 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 4 images.\n","I0720 15:12:15.671733 139766408148736 coco_evaluation.py:237] Performing evaluation on 4 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0720 15:12:15.672101 139766408148736 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0720 15:12:15.672481 139766408148736 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.828\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.832\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.835\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.835\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.835\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.840\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Finished evaluation at 2021-07-20-15:12:16\n","I0720 15:12:16.154334 139770316203904 evaluation.py:275] Finished evaluation at 2021-07-20-15:12:16\n","INFO:tensorflow:Saving dict for global step 8528: DetectionBoxes_Precision/mAP = 0.8280528, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.8320132, DetectionBoxes_Precision/mAP (small) = 0.7, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.835, DetectionBoxes_Recall/AR@10 = 0.835, DetectionBoxes_Recall/AR@100 = 0.835, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.84, DetectionBoxes_Recall/AR@100 (small) = 0.7, Loss/classification_loss = 0.032643132, Loss/localization_loss = 0.07678926, Loss/regularization_loss = 0.3398048, Loss/total_loss = 0.44923717, global_step = 8528, learning_rate = 0.004, loss = 0.44923717\n","I0720 15:12:16.154629 139770316203904 estimator.py:2049] Saving dict for global step 8528: DetectionBoxes_Precision/mAP = 0.8280528, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.8320132, DetectionBoxes_Precision/mAP (small) = 0.7, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.835, DetectionBoxes_Recall/AR@10 = 0.835, DetectionBoxes_Recall/AR@100 = 0.835, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.84, DetectionBoxes_Recall/AR@100 (small) = 0.7, Loss/classification_loss = 0.032643132, Loss/localization_loss = 0.07678926, Loss/regularization_loss = 0.3398048, Loss/total_loss = 0.44923717, global_step = 8528, learning_rate = 0.004, loss = 0.44923717\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8528: training/model.ckpt-8528\n","I0720 15:12:16.156276 139770316203904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 8528: training/model.ckpt-8528\n","INFO:tensorflow:global_step/sec: 1.21051\n","I0720 15:13:06.079072 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.21051\n","INFO:tensorflow:loss = 1.078963, step = 8600 (82.610 sec)\n","I0720 15:13:06.080320 139770316203904 basic_session_run_hooks.py:260] loss = 1.078963, step = 8600 (82.610 sec)\n","INFO:tensorflow:global_step/sec: 1.46627\n","I0720 15:14:14.279302 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46627\n","INFO:tensorflow:loss = 1.0753739, step = 8700 (68.200 sec)\n","I0720 15:14:14.280588 139770316203904 basic_session_run_hooks.py:260] loss = 1.0753739, step = 8700 (68.200 sec)\n","INFO:tensorflow:global_step/sec: 1.45757\n","I0720 15:15:22.886737 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.45757\n","INFO:tensorflow:loss = 1.0484333, step = 8800 (68.607 sec)\n","I0720 15:15:22.888077 139770316203904 basic_session_run_hooks.py:260] loss = 1.0484333, step = 8800 (68.607 sec)\n","INFO:tensorflow:global_step/sec: 1.46894\n","I0720 15:16:30.962798 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46894\n","INFO:tensorflow:loss = 0.90541345, step = 8900 (68.076 sec)\n","I0720 15:16:30.964204 139770316203904 basic_session_run_hooks.py:260] loss = 0.90541345, step = 8900 (68.076 sec)\n","INFO:tensorflow:global_step/sec: 1.46433\n","I0720 15:17:39.253297 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46433\n","INFO:tensorflow:loss = 1.0830581, step = 9000 (68.290 sec)\n","I0720 15:17:39.254687 139770316203904 basic_session_run_hooks.py:260] loss = 1.0830581, step = 9000 (68.290 sec)\n","INFO:tensorflow:global_step/sec: 1.46411\n","I0720 15:18:47.554183 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46411\n","INFO:tensorflow:loss = 1.0678942, step = 9100 (68.300 sec)\n","I0720 15:18:47.555175 139770316203904 basic_session_run_hooks.py:260] loss = 1.0678942, step = 9100 (68.300 sec)\n","INFO:tensorflow:global_step/sec: 1.4628\n","I0720 15:19:55.916200 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.4628\n","INFO:tensorflow:loss = 0.9262409, step = 9200 (68.362 sec)\n","I0720 15:19:55.917258 139770316203904 basic_session_run_hooks.py:260] loss = 0.9262409, step = 9200 (68.362 sec)\n","INFO:tensorflow:global_step/sec: 1.46245\n","I0720 15:21:04.294709 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46245\n","INFO:tensorflow:loss = 0.9576166, step = 9300 (68.379 sec)\n","I0720 15:21:04.296082 139770316203904 basic_session_run_hooks.py:260] loss = 0.9576166, step = 9300 (68.379 sec)\n","INFO:tensorflow:Saving checkpoints for 9385 into training/model.ckpt.\n","I0720 15:22:01.691430 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 9385 into training/model.ckpt.\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f19cad9aa50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 15:22:04.107103 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f19cad9aa50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1de03f78c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 15:22:04.266069 139770316203904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1de03f78c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0720 15:22:04.727614 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:22:06.651740 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:22:06.679283 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:22:06.705678 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:22:06.732406 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:22:06.758465 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:22:06.784613 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 15:22:08.800468 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 15:22:08.800782 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 15:22:08.801047 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 15:22:08.801222 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 15:22:08.801476 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 15:22:08.801652 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 15:22:08.801892 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 15:22:08.802058 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 15:22:08.802295 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 15:22:08.802469 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 15:22:08.802711 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 15:22:08.802876 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 15:22:08.803107 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 15:22:08.803277 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 15:22:08.803526 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 15:22:08.803699 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 15:22:08.803935 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 15:22:08.804096 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 15:22:08.804330 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 15:22:08.804500 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 15:22:08.804738 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 15:22:08.804903 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 15:22:08.805136 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 15:22:08.805299 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 15:22:08.805541 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 15:22:08.805712 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 15:22:08.805949 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 15:22:08.806113 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 15:22:08.806348 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 15:22:08.806520 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 15:22:08.806761 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 15:22:08.806926 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 15:22:08.807160 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 15:22:08.807324 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 15:22:08.807567 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 15:22:08.807747 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 15:22:08.807904 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 15:22:08.808064 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 15:22:08.808235 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 15:22:08.808407 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 15:22:08.808572 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 15:22:08.808744 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 15:22:08.808912 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I0720 15:22:09.673235 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-07-20T15:22:09Z\n","I0720 15:22:09.688439 139770316203904 evaluation.py:255] Starting evaluation at 2021-07-20T15:22:09Z\n","INFO:tensorflow:Graph was finalized.\n","I0720 15:22:10.370412 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 15:22:10.371116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:22:10.371434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:22:10.371523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:22:10.371548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:22:10.371579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:22:10.371607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:22:10.371629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:22:10.371648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:22:10.371667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:22:10.371755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:22:10.372016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:22:10.372209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:22:10.372287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 15:22:10.372302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 15:22:10.372311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 15:22:10.372422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:22:10.372683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:22:10.372897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-9385\n","I0720 15:22:10.373989 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-9385\n","INFO:tensorflow:Running local_init_op.\n","I0720 15:22:11.883055 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 15:22:12.058045 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 4 images.\n","I0720 15:22:15.177204 139766408148736 coco_evaluation.py:237] Performing evaluation on 4 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0720 15:22:15.177624 139766408148736 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0720 15:22:15.178986 139766408148736 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.05s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.791\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.805\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.805\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.805\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.813\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Finished evaluation at 2021-07-20-15:22:15\n","I0720 15:22:15.698954 139770316203904 evaluation.py:275] Finished evaluation at 2021-07-20-15:22:15\n","INFO:tensorflow:Saving dict for global step 9385: DetectionBoxes_Precision/mAP = 0.7910726, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.80042905, DetectionBoxes_Precision/mAP (small) = 0.6, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.805, DetectionBoxes_Recall/AR@10 = 0.805, DetectionBoxes_Recall/AR@100 = 0.805, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.81333333, DetectionBoxes_Recall/AR@100 (small) = 0.6, Loss/classification_loss = 0.019765787, Loss/localization_loss = 0.11964229, Loss/regularization_loss = 0.3390112, Loss/total_loss = 0.47841924, global_step = 9385, learning_rate = 0.004, loss = 0.47841924\n","I0720 15:22:15.699246 139770316203904 estimator.py:2049] Saving dict for global step 9385: DetectionBoxes_Precision/mAP = 0.7910726, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.80042905, DetectionBoxes_Precision/mAP (small) = 0.6, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.805, DetectionBoxes_Recall/AR@10 = 0.805, DetectionBoxes_Recall/AR@100 = 0.805, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.81333333, DetectionBoxes_Recall/AR@100 (small) = 0.6, Loss/classification_loss = 0.019765787, Loss/localization_loss = 0.11964229, Loss/regularization_loss = 0.3390112, Loss/total_loss = 0.47841924, global_step = 9385, learning_rate = 0.004, loss = 0.47841924\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9385: training/model.ckpt-9385\n","I0720 15:22:15.701101 139770316203904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 9385: training/model.ckpt-9385\n","INFO:tensorflow:global_step/sec: 1.2122\n","I0720 15:22:26.789311 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.2122\n","INFO:tensorflow:loss = 1.0360487, step = 9400 (82.494 sec)\n","I0720 15:22:26.790472 139770316203904 basic_session_run_hooks.py:260] loss = 1.0360487, step = 9400 (82.494 sec)\n","INFO:tensorflow:global_step/sec: 1.46022\n","I0720 15:23:35.271926 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46022\n","INFO:tensorflow:loss = 1.094204, step = 9500 (68.483 sec)\n","I0720 15:23:35.273313 139770316203904 basic_session_run_hooks.py:260] loss = 1.094204, step = 9500 (68.483 sec)\n","INFO:tensorflow:global_step/sec: 1.46535\n","I0720 15:24:43.514947 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46535\n","INFO:tensorflow:loss = 0.93416464, step = 9600 (68.243 sec)\n","I0720 15:24:43.516060 139770316203904 basic_session_run_hooks.py:260] loss = 0.93416464, step = 9600 (68.243 sec)\n","INFO:tensorflow:global_step/sec: 1.46279\n","I0720 15:25:51.877298 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46279\n","INFO:tensorflow:loss = 1.0851035, step = 9700 (68.363 sec)\n","I0720 15:25:51.878572 139770316203904 basic_session_run_hooks.py:260] loss = 1.0851035, step = 9700 (68.363 sec)\n","INFO:tensorflow:global_step/sec: 1.46319\n","I0720 15:27:00.221073 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.46319\n","INFO:tensorflow:loss = 0.98257077, step = 9800 (68.344 sec)\n","I0720 15:27:00.222259 139770316203904 basic_session_run_hooks.py:260] loss = 0.98257077, step = 9800 (68.344 sec)\n","INFO:tensorflow:global_step/sec: 1.47349\n","I0720 15:28:08.087154 139770316203904 basic_session_run_hooks.py:692] global_step/sec: 1.47349\n","INFO:tensorflow:loss = 0.8107844, step = 9900 (67.866 sec)\n","I0720 15:28:08.088148 139770316203904 basic_session_run_hooks.py:260] loss = 0.8107844, step = 9900 (67.866 sec)\n","INFO:tensorflow:Saving checkpoints for 10000 into training/model.ckpt.\n","I0720 15:29:15.408827 139770316203904 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into training/model.ckpt.\n","INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n","I0720 15:29:17.798055 139770316203904 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f19cb584090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","W0720 15:29:17.853075 139770316203904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f19cb584090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f19cb70e3b0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0720 15:29:18.011666 139770316203904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f19cb70e3b0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0720 15:29:18.472197 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:29:21.039543 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:29:21.068677 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:29:21.096869 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:29:21.124362 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:29:21.151692 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:29:21.177971 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 15:29:23.189774 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 15:29:23.190087 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 15:29:23.190352 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 15:29:23.190538 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 15:29:23.190789 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 15:29:23.190959 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 15:29:23.191196 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 15:29:23.191366 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 15:29:23.191632 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 15:29:23.191802 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 15:29:23.192039 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 15:29:23.192203 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 15:29:23.192447 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 15:29:23.192621 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 15:29:23.192857 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 15:29:23.193031 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 15:29:23.193274 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 15:29:23.193452 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 15:29:23.193696 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 15:29:23.193860 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 15:29:23.194095 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 15:29:23.194258 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 15:29:23.194504 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 15:29:23.194674 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 15:29:23.194917 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 15:29:23.195080 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 15:29:23.195319 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 15:29:23.195489 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 15:29:23.195749 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 15:29:23.195923 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 15:29:23.196201 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 15:29:23.196415 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 15:29:23.196741 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 15:29:23.196939 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 15:29:23.197213 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 15:29:23.197381 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 15:29:23.197564 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 15:29:23.197739 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 15:29:23.197929 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 15:29:23.198105 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 15:29:23.198297 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 15:29:23.198489 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 15:29:23.198726 139770316203904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I0720 15:29:24.120386 139770316203904 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-07-20T15:29:24Z\n","I0720 15:29:24.137445 139770316203904 evaluation.py:255] Starting evaluation at 2021-07-20T15:29:24Z\n","INFO:tensorflow:Graph was finalized.\n","I0720 15:29:24.890171 139770316203904 monitored_session.py:240] Graph was finalized.\n","2021-07-20 15:29:24.890907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:29:24.891239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:29:24.891332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:29:24.891360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:29:24.891386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:29:24.891426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:29:24.891452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:29:24.891474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:29:24.891497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:29:24.891588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:29:24.891871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:29:24.892087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:29:24.892145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 15:29:24.892160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 15:29:24.892171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 15:29:24.892273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:29:24.892620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:29:24.892854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n","I0720 15:29:24.893908 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n","INFO:tensorflow:Running local_init_op.\n","I0720 15:29:26.581802 139770316203904 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0720 15:29:26.772199 139770316203904 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 4 images.\n","I0720 15:29:29.992680 139766408148736 coco_evaluation.py:237] Performing evaluation on 4 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0720 15:29:29.993290 139766408148736 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0720 15:29:29.993927 139766408148736 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.05s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.839\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.852\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.850\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.850\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.850\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.862\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","INFO:tensorflow:Finished evaluation at 2021-07-20-15:29:30\n","I0720 15:29:30.523477 139770316203904 evaluation.py:275] Finished evaluation at 2021-07-20-15:29:30\n","INFO:tensorflow:Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.83920795, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.8523762, DetectionBoxes_Precision/mAP (small) = 0.6, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.85, DetectionBoxes_Recall/AR@10 = 0.85, DetectionBoxes_Recall/AR@100 = 0.85, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.8616667, DetectionBoxes_Recall/AR@100 (small) = 0.6, Loss/classification_loss = 0.008813534, Loss/localization_loss = 0.056412283, Loss/regularization_loss = 0.3384428, Loss/total_loss = 0.40366864, global_step = 10000, learning_rate = 0.004, loss = 0.40366864\n","I0720 15:29:30.523783 139770316203904 estimator.py:2049] Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.83920795, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.8523762, DetectionBoxes_Precision/mAP (small) = 0.6, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 1.0, DetectionBoxes_Recall/AR@1 = 0.85, DetectionBoxes_Recall/AR@10 = 0.85, DetectionBoxes_Recall/AR@100 = 0.85, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.8616667, DetectionBoxes_Recall/AR@100 (small) = 0.6, Loss/classification_loss = 0.008813534, Loss/localization_loss = 0.056412283, Loss/regularization_loss = 0.3384428, Loss/total_loss = 0.40366864, global_step = 10000, learning_rate = 0.004, loss = 0.40366864\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: training/model.ckpt-10000\n","I0720 15:29:30.525809 139770316203904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 10000: training/model.ckpt-10000\n","INFO:tensorflow:Performing the final export in the end of training.\n","I0720 15:29:30.526542 139770316203904 exporter.py:410] Performing the final export in the end of training.\n","INFO:tensorflow:Calling model_fn.\n","I0720 15:29:30.761526 139770316203904 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:29:32.782510 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:29:32.819378 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:29:32.847450 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:29:32.874886 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:29:32.905490 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:29:32.933979 139770316203904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0720 15:29:33.701656 139770316203904 estimator.py:1150] Done calling model_fn.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0720 15:29:33.701944 139770316203904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","I0720 15:29:33.702524 139770316203904 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","I0720 15:29:33.702648 139770316203904 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","I0720 15:29:33.702730 139770316203904 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","I0720 15:29:33.702801 139770316203904 export_utils.py:170] Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","I0720 15:29:33.702867 139770316203904 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n","2021-07-20 15:29:33.703344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:29:33.703655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:29:33.703739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:29:33.703764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:29:33.703783: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:29:33.703803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:29:33.703826: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:29:33.703849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:29:33.703870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:29:33.703955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:29:33.704219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:29:33.704427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:29:33.704468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 15:29:33.704483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 15:29:33.704492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 15:29:33.704595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:29:33.704864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:29:33.705073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n","I0720 15:29:33.707180 139770316203904 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n","INFO:tensorflow:Assets added to graph.\n","I0720 15:29:34.195326 139770316203904 builder_impl.py:665] Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","I0720 15:29:34.195566 139770316203904 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1626794970'/saved_model.pb\n","I0720 15:29:35.009329 139770316203904 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1626794970'/saved_model.pb\n","INFO:tensorflow:Loss for final step: 1.1213691.\n","I0720 15:29:35.699810 139770316203904 estimator.py:371] Loss for final step: 1.1213691.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KP-tUdtnRybs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626794987499,"user_tz":420,"elapsed":306,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"91d405e2-be12-4e20-90d3-192ac3f483d8"},"source":["#model dir check for the trained model\n","!ls {model_dir}"],"execution_count":16,"outputs":[{"output_type":"stream","text":["checkpoint\n","eval_0\n","events.out.tfevents.1626787879.18b391520366\n","export\n","graph.pbtxt\n","model.ckpt-10000.data-00000-of-00001\n","model.ckpt-10000.index\n","model.ckpt-10000.meta\n","model.ckpt-6811.data-00000-of-00001\n","model.ckpt-6811.index\n","model.ckpt-6811.meta\n","model.ckpt-7668.data-00000-of-00001\n","model.ckpt-7668.index\n","model.ckpt-7668.meta\n","model.ckpt-8528.data-00000-of-00001\n","model.ckpt-8528.index\n","model.ckpt-8528.meta\n","model.ckpt-9385.data-00000-of-00001\n","model.ckpt-9385.index\n","model.ckpt-9385.meta\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OmSESMetj1sa"},"source":["## Export a Trained Inference Graph\n","Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"]},{"cell_type":"code","metadata":{"id":"zZJ_AF5MD3hZ","executionInfo":{"status":"ok","timestamp":1626794991839,"user_tz":420,"elapsed":154,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}}},"source":["#clean output_directory if necessary to start fresh:\n","\n","!rm -rf /content/fine_tuned_model/ \n","os.makedirs('/content/fine_tuned_model/', exist_ok=True)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHoP90pUyKSq","executionInfo":{"status":"ok","timestamp":1626795011313,"user_tz":420,"elapsed":17356,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}}},"source":["%%capture\n","import re\n","import numpy as np\n","\n","output_directory = './fine_tuned_model'\n","# output_directory = '/content/gdrive/My\\ Drive/data/'\n","\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"usgBZvkz0nqD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626795014343,"user_tz":420,"elapsed":274,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"f12c2f11-41d5-465a-e461-bd7474d63f31"},"source":["#export directory check\n","!ls {output_directory}"],"execution_count":19,"outputs":[{"output_type":"stream","text":["checkpoint\t\t\tmodel.ckpt.index  saved_model\n","frozen_inference_graph.pb\tmodel.ckpt.meta\n","model.ckpt.data-00000-of-00001\tpipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CnDo1lonKgFr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626795017094,"user_tz":420,"elapsed":143,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"f93b9693-ff8e-4f37-ad20-ac589a525cae"},"source":["import os\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)\n","!ls -alh {pb_fname}"],"execution_count":20,"outputs":[{"output_type":"stream","text":["-rw-r--r-- 1 root root 19M Jul 20 15:30 /content/models/research/fine_tuned_model/frozen_inference_graph.pb\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mz1gX19GlVW7"},"source":["## Running Inference: Checking what the trained model can detect\n","Test with images in repository `object_detection_demo_flow/data/images/final test` directory."]},{"cell_type":"code","metadata":{"id":"Pzj9A4e5mj5l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626795019497,"user_tz":420,"elapsed":141,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"472c41fa-d51b-48d1-eae8-b005941c6c6e"},"source":["import os\n","import glob\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = pb_fname\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"models/object_detection/data/images/final_test\")\n","\n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["['/content/arnie/models/object_detection/data/images/final_test/new_signs_1626736569.jpg', '/content/arnie/models/object_detection/data/images/final_test/new_signs_1626737003.jpg', '/content/arnie/models/object_detection/data/images/final_test/new_signs_1626736474.jpg', '/content/arnie/models/object_detection/data/images/final_test/new_signs_1626736877.jpg']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CG5YUMdg1Po7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626795033869,"user_tz":420,"elapsed":9151,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"6940adef-8d2b-44a7-def0-f6affa9c83dd"},"source":["%cd /content/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","# This is needed to display the images.\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util\n","\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n","\n","for image_path in TEST_IMAGE_PATHS:\n","    image = Image.open(image_path)\n","    print(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=8)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)\n","    plt.show()"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/content/models/research/object_detection\n","/content/arnie/models/object_detection/data/images/final_test/new_signs_1626736569.jpg\n","/content/arnie/models/object_detection/data/images/final_test/new_signs_1626737003.jpg\n","/content/arnie/models/object_detection/data/images/final_test/new_signs_1626736474.jpg\n","/content/arnie/models/object_detection/data/images/final_test/new_signs_1626736877.jpg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZXjfNFc2eqJM","executionInfo":{"status":"aborted","timestamp":1626571322910,"user_tz":420,"elapsed":8,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_CvC6Br-eyo3"},"source":["## Export Trained Inference Graph\n","Export the newly trained inference graph to be used for object detection"]},{"cell_type":"code","metadata":{"id":"mB05rzgoeyo4","executionInfo":{"status":"ok","timestamp":1626795113470,"user_tz":420,"elapsed":137,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}}},"source":["import os\n","import re\n","import numpy as np\n","\n","model_dir = '/content/fine_tuned_model'\n","output_directory = '%s/fine_tuned_model_export' % model_dir\n","os.makedirs(output_directory, exist_ok=True)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"j9Ux9aEGgeBc","executionInfo":{"status":"ok","timestamp":1626795118564,"user_tz":420,"elapsed":148,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}}},"source":["last_model_path = '/content/models/research/fine_tuned_model/model.ckpt'"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bzj1RQRhzJ2D","executionInfo":{"status":"ok","timestamp":1626795122329,"user_tz":420,"elapsed":2102,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"b1ebfa5f-94c2-41ab-82e5-a1b2f54d1653"},"source":["def representative_dataset_gen():\n","  data = tfds.load(...)\n","\n","  for _ in range(num_calibration_steps):\n","    image, = data.take(1)\n","    yield [image]\n","\n","converter = tf.lite.TFLiteConverter.from_saved_model('/content/models/research/fine_tuned_model/saved_model')\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.representative_dataset = tf.lite.RepresentativeDataset(\n","    representative_dataset_gen)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n","INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n","INFO:tensorflow:input tensors info: \n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: inputs\n","INFO:tensorflow: tensor name: image_tensor:0, shape: (-1, -1, -1, 3), type: DT_UINT8\n","INFO:tensorflow:output tensors info: \n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: raw_detection_scores\n","INFO:tensorflow: tensor name: raw_detection_scores:0, shape: (-1, -1, 6), type: DT_FLOAT\n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_scores\n","INFO:tensorflow: tensor name: detection_scores:0, shape: (-1, 100), type: DT_FLOAT\n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: num_detections\n","INFO:tensorflow: tensor name: num_detections:0, shape: (-1), type: DT_FLOAT\n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: raw_detection_boxes\n","INFO:tensorflow: tensor name: raw_detection_boxes:0, shape: (-1, -1, 4), type: DT_FLOAT\n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_boxes\n","INFO:tensorflow: tensor name: detection_boxes:0, shape: (-1, 100, 4), type: DT_FLOAT\n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_classes\n","INFO:tensorflow: tensor name: detection_classes:0, shape: (-1, 100), type: DT_FLOAT\n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_multiclass_scores\n","INFO:tensorflow: tensor name: detection_multiclass_scores:0, shape: (-1, 100, 6), type: DT_FLOAT\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hlxqSTTgHMHO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626795142489,"user_tz":420,"elapsed":17474,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"a135ea04-c578-4c6e-df37-c9a592a184c7"},"source":["!echo creates the frozen inference graph in fine_tune_model\n","# there is an \"Incomplete shape\" message.  but we can safely ignore that. \n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory='{output_directory}' \\\n","    --trained_checkpoint_prefix='{last_model_path}'"],"execution_count":26,"outputs":[{"output_type":"stream","text":["creates the frozen inference graph in fine_tune_model\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0720 15:32:07.764777 140228409792384 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:32:09.793574 140228409792384 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:32:09.829371 140228409792384 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:32:09.867414 140228409792384 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:32:09.908966 140228409792384 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:32:09.948462 140228409792384 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:32:09.988025 140228409792384 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:583: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0720 15:32:10.244588 140228409792384 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:583: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0720 15:32:10.691107 140228409792384 deprecation.py:323] From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 15:32:12.227312 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 15:32:12.227672 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 15:32:12.227951 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 15:32:12.228137 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 15:32:12.228388 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 15:32:12.228580 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 15:32:12.228843 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 15:32:12.229022 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 15:32:12.229263 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 15:32:12.229470 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 15:32:12.229757 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 15:32:12.229953 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 15:32:12.230220 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 15:32:12.230435 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 15:32:12.230698 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 15:32:12.230901 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 15:32:12.231145 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 15:32:12.231316 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 15:32:12.231565 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 15:32:12.231750 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 15:32:12.232002 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 15:32:12.232195 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 15:32:12.232455 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 15:32:12.232636 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 15:32:12.232880 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 15:32:12.233057 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 15:32:12.233316 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 15:32:12.233500 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 15:32:12.233753 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 15:32:12.233928 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 15:32:12.234204 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 15:32:12.234401 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 15:32:12.234659 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 15:32:12.234832 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 15:32:12.235069 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 15:32:12.235235 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 15:32:12.235410 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 15:32:12.235580 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 15:32:12.235756 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 15:32:12.235929 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 15:32:12.236142 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 15:32:12.236314 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 15:32:12.236490 140228409792384 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0720 15:32:12.238783 140228409792384 deprecation.py:323] From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0720 15:32:12.239725 140228409792384 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","261 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/4.64m params)\n","  BoxPredictor_0 (--/17.31k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","    BoxPredictor_0/ClassPredictor (--/10.39k params)\n","      BoxPredictor_0/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x576x18, 10.37k/10.37k params)\n","  BoxPredictor_1 (--/76.86k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","    BoxPredictor_1/ClassPredictor (--/46.12k params)\n","      BoxPredictor_1/ClassPredictor/biases (36, 36/36 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1280x36, 46.08k/46.08k params)\n","  BoxPredictor_2 (--/30.78k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/18.47k params)\n","      BoxPredictor_2/ClassPredictor/biases (36, 36/36 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x36, 18.43k/18.43k params)\n","  BoxPredictor_3 (--/15.42k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/9.25k params)\n","      BoxPredictor_3/ClassPredictor/biases (36, 36/36 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x36, 9.22k/9.22k params)\n","  BoxPredictor_4 (--/15.42k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/9.25k params)\n","      BoxPredictor_4/ClassPredictor/biases (36, 36/36 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x36, 9.22k/9.22k params)\n","  BoxPredictor_5 (--/7.74k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/4.64k params)\n","      BoxPredictor_5/ClassPredictor/biases (36, 36/36 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x36, 4.61k/4.61k params)\n","  FeatureExtractor (--/4.48m params)\n","    FeatureExtractor/MobilenetV2 (--/4.48m params)\n","      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n","        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n","        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","\n","======================End of Report==========================\n","261 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/4.49m flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/mul_fold (1.18m/1.18m flops)\n","  FeatureExtractor/MobilenetV2/Conv_1/mul_fold (409.60k/409.60k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/mul_fold (327.68k/327.68k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_16/project/mul_fold (307.20k/307.20k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_16/expand/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_15/project/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_15/expand/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_14/project/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_14/expand/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_13/project/mul_fold (92.16k/92.16k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/mul_fold (73.73k/73.73k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/mul_fold (65.54k/65.54k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_11/expand/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_11/project/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_12/expand/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_12/project/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_13/expand/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_10/project/mul_fold (36.86k/36.86k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/mul_fold (32.77k/32.77k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_9/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_9/project/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_8/project/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_8/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_7/project/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_7/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_10/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/mul_fold (16.38k/16.38k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_6/project/mul_fold (12.29k/12.29k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/mul_fold (8.64k/8.64k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/mul_fold (8.64k/8.64k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/mul_fold (8.64k/8.64k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_4/expand/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_6/expand/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_5/project/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_5/expand/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_4/project/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/mul_fold (5.18k/5.18k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/mul_fold (5.18k/5.18k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/mul_fold (5.18k/5.18k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_3/project/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_3/expand/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_2/project/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_2/expand/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_1/project/mul_fold (2.30k/2.30k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/mul_fold (1.73k/1.73k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/mul_fold (1.73k/1.73k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/mul_fold (1.73k/1.73k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_1/expand/mul_fold (1.54k/1.54k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/mul_fold (1.30k/1.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/mul_fold (1.30k/1.30k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/mul_fold (864/864 flops)\n","  FeatureExtractor/MobilenetV2/Conv/mul_fold (864/864 flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv/project/mul_fold (512/512 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv/depthwise/mul_fold (288/288 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","\n","======================End of Report==========================\n","2021-07-20 15:32:15.142034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-07-20 15:32:15.146730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:15.147250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:32:15.147522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:32:15.148958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:32:15.150547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:32:15.150879: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:32:15.152933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:32:15.162834: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:32:15.169168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:32:15.169277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:15.169824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:15.170293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:32:15.190628: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2021-07-20 15:32:15.190850: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5564fa2d2bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 15:32:15.190881: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-07-20 15:32:15.410488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:15.411253: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5564fa2d3480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 15:32:15.411284: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2021-07-20 15:32:15.411485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:15.411983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:32:15.412047: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:32:15.412073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:32:15.412094: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:32:15.412121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:32:15.412142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:32:15.412160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:32:15.412180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:32:15.412254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:15.412831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:15.413292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:32:15.413367: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:32:15.414474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 15:32:15.414498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 15:32:15.414509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 15:32:15.414648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:15.415232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:15.415796: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-07-20 15:32:15.415839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13133 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/models/research/fine_tuned_model/model.ckpt\n","I0720 15:32:15.417410 140228409792384 saver.py:1284] Restoring parameters from /content/models/research/fine_tuned_model/model.ckpt\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0720 15:32:17.510134 140228409792384 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2021-07-20 15:32:18.434522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:18.435084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:32:18.435186: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:32:18.435217: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:32:18.435239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:32:18.435268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:32:18.435289: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:32:18.435308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:32:18.435327: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:32:18.435434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:18.435963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:18.436427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:32:18.436466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 15:32:18.436482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 15:32:18.436492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 15:32:18.436582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:18.437094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:18.437576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13133 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/models/research/fine_tuned_model/model.ckpt\n","I0720 15:32:18.438546 140228409792384 saver.py:1284] Restoring parameters from /content/models/research/fine_tuned_model/model.ckpt\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0720 15:32:19.607283 140228409792384 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0720 15:32:19.607548 140228409792384 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 632 variables.\n","I0720 15:32:20.229202 140228409792384 graph_util_impl.py:334] Froze 632 variables.\n","INFO:tensorflow:Converted 632 variables to const ops.\n","I0720 15:32:20.328961 140228409792384 graph_util_impl.py:394] Converted 632 variables to const ops.\n","2021-07-20 15:32:20.503122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:20.503783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:32:20.503876: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:32:20.503903: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:32:20.503928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:32:20.503951: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:32:20.503973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:32:20.503995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:32:20.504018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:32:20.504114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:20.504728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:20.505254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:32:20.505296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 15:32:20.505313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 15:32:20.505323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 15:32:20.505434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:20.506026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:20.506570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13133 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0720 15:32:21.184947 140228409792384 deprecation.py:323] From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:No assets to save.\n","I0720 15:32:21.185878 140228409792384 builder_impl.py:640] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0720 15:32:21.186051 140228409792384 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: /content/fine_tuned_model/fine_tuned_model_export/saved_model/saved_model.pb\n","I0720 15:32:21.502843 140228409792384 builder_impl.py:425] SavedModel written to: /content/fine_tuned_model/fine_tuned_model_export/saved_model/saved_model.pb\n","INFO:tensorflow:Writing pipeline config file to /content/fine_tuned_model/fine_tuned_model_export/pipeline.config\n","I0720 15:32:21.529231 140228409792384 config_util.py:254] Writing pipeline config file to /content/fine_tuned_model/fine_tuned_model_export/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kwsBovsWZV_S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626795153985,"user_tz":420,"elapsed":11379,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"af7403e5-2523-4306-b558-07cdbd108313"},"source":["# https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193\n","# create the tensorflow lite graph\n","!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --trained_checkpoint_prefix='{last_model_path}' \\\n","    --output_directory='{output_directory}' \\\n","    --add_postprocessing_op=true"],"execution_count":27,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0720 15:32:25.173091 140152318547840 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:32:27.263808 140152318547840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:32:27.293320 140152318547840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:32:27.325209 140152318547840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:32:27.355709 140152318547840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:32:27.382667 140152318547840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0720 15:32:27.410669 140152318547840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","2021-07-20 15:32:27.452724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-07-20 15:32:27.457513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:27.458107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:32:27.458357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:32:27.459862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:32:27.465769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:32:27.466079: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:32:27.467617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:32:27.470132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:32:27.473694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:32:27.473799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:27.474370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:27.474854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:32:27.479743: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2021-07-20 15:32:27.479907: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556eb4b65480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 15:32:27.479931: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-07-20 15:32:27.695858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:27.696632: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556eb4b65640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 15:32:27.696664: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2021-07-20 15:32:27.696832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:27.697361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:32:27.697456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:32:27.697487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:32:27.697508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:32:27.697531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:32:27.697550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:32:27.697568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:32:27.697588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:32:27.697664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:27.698196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:27.698709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:32:27.698784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:32:27.699924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 15:32:27.699954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 15:32:27.699964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 15:32:27.700076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:27.700617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:27.701123: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-07-20 15:32:27.701165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13133 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0720 15:32:29.296319 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0720 15:32:29.296684 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0720 15:32:29.296987 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0720 15:32:29.297176 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0720 15:32:29.297445 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0720 15:32:29.297633 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0720 15:32:29.297909 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0720 15:32:29.298132 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0720 15:32:29.298413 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0720 15:32:29.298595 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0720 15:32:29.298859 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0720 15:32:29.299036 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0720 15:32:29.299291 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0720 15:32:29.299481 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0720 15:32:29.299756 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0720 15:32:29.299935 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0720 15:32:29.300189 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0720 15:32:29.300416 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0720 15:32:29.300796 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0720 15:32:29.301039 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0720 15:32:29.301310 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0720 15:32:29.301502 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0720 15:32:29.301765 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0720 15:32:29.301947 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0720 15:32:29.302202 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0720 15:32:29.302379 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0720 15:32:29.302647 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0720 15:32:29.302828 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0720 15:32:29.303080 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0720 15:32:29.303258 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0720 15:32:29.303518 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0720 15:32:29.303704 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0720 15:32:29.303962 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0720 15:32:29.304141 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0720 15:32:29.304403 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0720 15:32:29.304574 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0720 15:32:29.304756 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0720 15:32:29.304939 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0720 15:32:29.305111 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0720 15:32:29.305284 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0720 15:32:29.305484 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0720 15:32:29.305694 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0720 15:32:29.305897 140152318547840 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0720 15:32:29.805658 140152318547840 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2021-07-20 15:32:30.393485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:30.394066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:32:30.394156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:32:30.394181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:32:30.394202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:32:30.394222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:32:30.394246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:32:30.394264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:32:30.394285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:32:30.394370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:30.394943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:30.395414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:32:30.395452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 15:32:30.395466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 15:32:30.395476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 15:32:30.395570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:30.396119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:30.396612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13133 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/models/research/fine_tuned_model/model.ckpt\n","I0720 15:32:30.397552 140152318547840 saver.py:1284] Restoring parameters from /content/models/research/fine_tuned_model/model.ckpt\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0720 15:32:31.695247 140152318547840 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0720 15:32:31.695540 140152318547840 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 632 variables.\n","I0720 15:32:32.337758 140152318547840 graph_util_impl.py:334] Froze 632 variables.\n","INFO:tensorflow:Converted 632 variables to const ops.\n","I0720 15:32:32.413161 140152318547840 graph_util_impl.py:394] Converted 632 variables to const ops.\n","2021-07-20 15:32:32.540509: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uTikaJKpK6No","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626795162555,"user_tz":420,"elapsed":5371,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"4ff4d112-39f8-4b16-e239-71a43dae7a83"},"source":["!echo \"CONVERTING frozen graph to quantized TF Lite file...\"\n","!tflite_convert \\\n","  --output_file='{output_directory}/road_signs_quantized_1.tflite' \\\n","  --graph_def_file='{output_directory}/tflite_graph.pb' \\\n","  --inference_type=QUANTIZED_UINT8 \\\n","  --input_arrays='normalized_input_image_tensor' \\\n","  --output_arrays='TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3' \\\n","  --mean_values=128 \\\n","  --std_dev_values=128 \\\n","  --input_shapes=1,300,300,3 \\\n","  --change_concat_input_ranges=false \\\n","  --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n","  --allow_custom_ops"],"execution_count":28,"outputs":[{"output_type":"stream","text":["CONVERTING frozen graph to quantized TF Lite file...\n","2021-07-20 15:32:38.936533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-07-20 15:32:38.940739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:38.941250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:32:38.941497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:32:38.942971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:32:38.945976: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:32:38.946288: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:32:38.947836: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:32:38.948831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:32:38.952222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:32:38.952323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:38.952891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:38.953423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:32:38.958575: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2021-07-20 15:32:38.958753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a505b10bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 15:32:38.958778: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-07-20 15:32:39.182996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:39.183767: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a505b10d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 15:32:39.183801: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2021-07-20 15:32:39.183965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:39.184485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 15:32:39.184547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:32:39.184567: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 15:32:39.184587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 15:32:39.184604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 15:32:39.184627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 15:32:39.184646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 15:32:39.184666: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 15:32:39.184735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:39.185235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:39.185715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 15:32:39.185770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 15:32:39.186690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 15:32:39.186714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 15:32:39.186726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 15:32:39.186829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:39.187335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 15:32:39.187823: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-07-20 15:32:39.187861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13133 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RsZi5SHSSVur","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626721041316,"user_tz":420,"elapsed":6385,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"e9052d7e-43b2-489a-8991-3958fadcff82"},"source":["!echo \"CONVERTING frozen graph to unquantized TF Lite file...\"\n","!tflite_convert \\\n","  --output_file='{output_directory}/road_signs_float.tflite' \\\n","  --graph_def_file='{output_directory}/tflite_graph.pb' \\\n","  --input_arrays='normalized_input_image_tensor' \\\n","  --output_arrays='TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3' \\\n","  --mean_values=128 \\\n","  --std_dev_values=128 \\\n","  --input_shapes=1,300,300,3 \\\n","  --change_concat_input_ranges=false \\\n","  --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n","  --allow_custom_ops \n"],"execution_count":31,"outputs":[{"output_type":"stream","text":["CONVERTING frozen graph to unquantized TF Lite file...\n","2021-07-19 18:57:17.107597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-07-19 18:57:17.112215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-19 18:57:17.113267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-19 18:57:17.113524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-19 18:57:17.115128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-19 18:57:17.116991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-19 18:57:17.117355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-19 18:57:17.119097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-19 18:57:17.120369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-19 18:57:17.124591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-19 18:57:17.124694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-19 18:57:17.125430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-19 18:57:17.125997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-19 18:57:17.131760: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2021-07-19 18:57:17.132077: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ce3891ebc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-07-19 18:57:17.132132: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-07-19 18:57:17.336734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-19 18:57:17.338066: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ce3891ed80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-07-19 18:57:17.338102: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2021-07-19 18:57:17.338350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-19 18:57:17.339340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-19 18:57:17.339434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-19 18:57:17.339480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-19 18:57:17.339522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-19 18:57:17.339574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-19 18:57:17.339612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-19 18:57:17.339684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-19 18:57:17.339726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-19 18:57:17.339848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-19 18:57:17.340934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-19 18:57:17.341901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-19 18:57:17.341994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-19 18:57:17.343241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-19 18:57:17.343273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-19 18:57:17.343297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-19 18:57:17.343426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-19 18:57:17.344154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-19 18:57:17.344877: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-07-19 18:57:17.344930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13133 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hxbybBTbeyo6","executionInfo":{"status":"ok","timestamp":1626795177936,"user_tz":420,"elapsed":475,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"f5da4afa-d032-48d0-ec1c-1293c4078f0e"},"source":["print(output_directory)\n","!ls -ltra '{output_directory}'\n","#pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\") # this is main one\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")  # this is tflite graph\n","!cp '{label_map_pbtxt_fname}' '{output_directory}'"],"execution_count":29,"outputs":[{"output_type":"stream","text":["/content/fine_tuned_model/fine_tuned_model_export\n","total 116192\n","drwxr-xr-x 3 root root     4096 Jul 20 15:31 ..\n","-rw-r--r-- 1 root root 18857216 Jul 20 15:32 model.ckpt.data-00000-of-00001\n","-rw-r--r-- 1 root root    23543 Jul 20 15:32 model.ckpt.index\n","-rw-r--r-- 1 root root       77 Jul 20 15:32 checkpoint\n","-rw-r--r-- 1 root root  2204025 Jul 20 15:32 model.ckpt.meta\n","-rw-r--r-- 1 root root 19734989 Jul 20 15:32 frozen_inference_graph.pb\n","drwxr-xr-x 3 root root     4096 Jul 20 15:32 saved_model\n","-rw-r--r-- 1 root root     4176 Jul 20 15:32 pipeline.config\n","-rw-r--r-- 1 root root 19342722 Jul 20 15:32 tflite_graph.pb\n","-rw-r--r-- 1 root root 54000701 Jul 20 15:32 tflite_graph.pbtxt\n","-rw-r--r-- 1 root root  4777024 Jul 20 15:32 road_signs_quantized_1.tflite\n","drwxr-xr-x 3 root root     4096 Jul 20 15:32 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rJvm308F69oj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RZatNsloxg8q"},"source":["## Compile TF Lite model for Edge TPU"]},{"cell_type":"code","metadata":{"id":"itv0Kj7N6ALw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626795188580,"user_tz":420,"elapsed":138,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"4be0c6cb-e8d2-4463-eeaf-57f97c464c41"},"source":["# Load quantized road signs model\n","%env TFLITE_FILE=/content/fine_tuned_model/fine_tuned_model_export/road_signs_quantized_1.tflite"],"execution_count":30,"outputs":[{"output_type":"stream","text":["env: TFLITE_FILE=/content/fine_tuned_model/fine_tuned_model_export/road_signs_quantized_1.tflite\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9JPzsCxm05Qj"},"source":["### Get the Edge TPU Compiler"]},{"cell_type":"code","metadata":{"id":"p6ZpWgrk21Ad","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626795201984,"user_tz":420,"elapsed":11509,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"8b7a8226-f283-4f76-a479-6e8968178061"},"source":["! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n","\n","! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n","\n","! sudo apt-get update\n","\n","! sudo apt-get install edgetpu-compiler\t"],"execution_count":31,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0  93962      0 --:--:-- --:--:-- --:--:-- 97576\n","OK\n","deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:7 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,722 B]\n","Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:11 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:14 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [2,332 B]\n","Hit:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Fetched 261 kB in 1s (209 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following NEW packages will be installed:\n","  edgetpu-compiler\n","0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n","Need to get 7,865 kB of archives.\n","After this operation, 31.2 MB of additional disk space will be used.\n","Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 15.0 [7,865 kB]\n","Fetched 7,865 kB in 1s (13.7 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package edgetpu-compiler.\n","(Reading database ... 161222 files and directories currently installed.)\n","Preparing to unpack .../edgetpu-compiler_15.0_amd64.deb ...\n","Unpacking edgetpu-compiler (15.0) ...\n","Setting up edgetpu-compiler (15.0) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mtPcYiER3Ymp"},"source":["### Compile the model"]},{"cell_type":"code","metadata":{"id":"joxrIB0I3cdi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626795213031,"user_tz":420,"elapsed":1294,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"8118a6aa-773d-4fcb-b3c1-15a2ba76ee08"},"source":["! edgetpu_compiler $TFLITE_FILE"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Edge TPU Compiler version 15.0.340273435\n","\n","Model compiled successfully in 945 ms.\n","\n","Input model: /content/fine_tuned_model/fine_tuned_model_export/road_signs_quantized_1.tflite\n","Input size: 4.56MiB\n","Output model: road_signs_quantized_1_edgetpu.tflite\n","Output size: 5.16MiB\n","On-chip memory used for caching model parameters: 5.01MiB\n","On-chip memory remaining for caching model parameters: 2.73MiB\n","Off-chip memory used for streaming uncached model parameters: 0.00B\n","Number of Edge TPU subgraphs: 1\n","Total number of operations: 99\n","Operation log: road_signs_quantized_1_edgetpu.log\n","\n","Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n","Number of operations that will run on Edge TPU: 98\n","Number of operations that will run on CPU: 1\n","See the operation log file for individual operation details.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7R8JMQc1MMm5"},"source":["The compiled model uses the same filename but with \"_edgetpu\" appended at the end.\n","\n","If the compilation failed, check the **Files** panel on the left for the `.log` file that contains more details. (You might need to click the **Refresh** button to see the new files.)\n"]},{"cell_type":"markdown","metadata":{"id":"Oi9-Voc8A7VK"},"source":["### Download the model"]},{"cell_type":"markdown","metadata":{"id":"XiugMm-jBbWl"},"source":["You can download the converted model from Colab with this: "]},{"cell_type":"code","metadata":{"id":"x47uW_lI1DoV","colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"status":"error","timestamp":1626795226443,"user_tz":420,"elapsed":1128,"user":{"displayName":"Warren Harper","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggplxs1x4JJ6UH0OGYcrCOB6aQ00NiSJljkVZa0YQ=s64","userId":"06912581651236558568"}},"outputId":"47e51f6b-14af-4813-e581-791d343383da"},"source":["import os\n","from google.colab import files\n","\n","name = os.path.splitext(os.environ['TFLITE_FILE'])[0]\n","files.download(str(name + '_edgetpu.tflite'))"],"execution_count":33,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-f3ef964a6bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TFLITE_FILE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_edgetpu.tflite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/fine_tuned_model/fine_tuned_model_export/road_signs_quantized_1_edgetpu.tflite"]}]},{"cell_type":"markdown","metadata":{"id":"_qOCP3mXXvsm"},"source":["If you get a \"Failed to fetch\" error here, it's probably because the files weren't done saving. So just wait a moment and try again."]}]}